# HeterogeneousParallelization_Assignment4

# Assignment 4: Гибридные и распределённые параллельные вычисления

**Astana IT University**

**Course:** Heterogeneous Parallelization

**Course instructor:** Садвакасова Куралай Жанжигитовна

**Student:** Жумагулова Карина

**Group:** ADA-2403M

**Date:** 25.01.2026

Данный репозиторий содержит решения Assignment 4, посвящённого изучению **гибридных и распределённых параллельных вычислений**. Работа демонстрирует:

* использование **GPU с глобальной и shared памятью**,
* реализацию **гибридной программы на CPU+GPU**,
* распределённые вычисления с использованием **MPI**,
* измерение времени выполнения и сравнение различных подходов.

## Структура репозитория

```
.
├── HP_Assignment_4.ipynb          # Объединённые заметки и тесты всех заданий
├── task_1.cu                      # Задание 1: Сумма элементов массива на GPU (global memory)
├── task_2.cu                      # Задание 2: Префиксная сумма с shared memory
├── task_3_1.cu                    # Задание 3: Гибридная обработка массива CPU+GPU
├── task_4.cpp                     # Задание 4: Распределённая обработка массива с MPI
├── questions.md                  # Ответы на контрольные вопросы Assignment 4
├── README.md                     # Описание проекта и структура репозитория
```

---

## Задание 1 (task1.cu)

**Описание:**

Реализация CUDA-программы для **вычисления суммы элементов массива** с использованием **глобальной памяти GPU**. Сравнивается с последовательной реализацией на CPU для массива размером 100 000 элементов.

**Цель задания:**

* Изучить работу глобальной памяти на GPU.
* Сравнить производительность CPU и GPU.
* Научиться измерять время выполнения с помощью `cudaEvent_t`.

**Функционал программы:**

1. Инициализация массива из 100 000 случайных чисел.
2. Вычисление суммы элементов на CPU (последовательно).
3. Вычисление суммы на GPU с использованием глобальной памяти.
4. Вывод первых и последних 10 элементов массива для проверки.
5. Сравнение времени выполнения CPU и GPU.

**Используемые технологии:**

* **C++ / CUDA**, глобальная память GPU, `cudaEvent_t`, `std::vector`, генерация случайных чисел через Mersenne Twister.

## Задание 2 (task2.cu)

**Описание:**

Реализация **префиксной суммы (scan)** массива с использованием **shared memory GPU**. Сравнение с последовательной версией на CPU для массива 1 000 000 элементов.

**Цель задания:**

* Изучить работу shared memory внутри блока потоков.
* Оценить ускорение GPU по сравнению с CPU при параллельной обработке.
* Научиться реализовывать Hillis–Steele scan с использованием CUDA.

**Функционал программы:**

1. Генерация массива 1 000 000 случайных чисел.
2. Вычисление префиксной суммы на CPU (последовательно).
3. Реализация параллельного сканирования на GPU с использованием shared memory.
4. Вывод первых и последних 10 элементов для проверки.
5. Сравнение времени выполнения CPU и GPU.

**Используемые технологии:**

* **C++ / CUDA**, shared memory, `cudaEvent_t`, динамические массивы и генерация случайных чисел.

## Задание 3 (task3.cu)

**Описание:**

Гибридная программа, в которой **первая половина массива обрабатывается на CPU, вторая — на GPU**. Операция обработки: **умножение элементов массива на 2**.

**Цель задания:**

* Изучить **гибридные вычисления** и взаимодействие CPU и GPU.
* Замерить время выполнения полностью на CPU, GPU и в гибридной конфигурации.
* Научиться комбинировать локальную и GPU-обработку данных.

**Функционал программы:**

1. Генерация массива 1 000 000 случайных чисел.
2. Обработка всей половины массива на CPU.
3. Обработка второй половины на GPU с использованием CUDA.
4. Вывод первых и последних 10 элементов исходного и обработанного массивов.
5. Замеры времени выполнения всех трёх вариантов (CPU, GPU, гибрид).

**Используемые технологии:**

* **C++ / CUDA**, глобальная память, `cudaEvent_t`, измерение времени, std::vector.

## Задание 4 (task4.cpp)

**Описание:**

Распределённая программа с использованием **MPI**, в которой массив данных разделяется между процессами, локально обрабатывается (умножение на 2) и собирается обратно. Замеры времени выполняются для 2, 4 и 8 процессов.

**Цель задания:**

* Изучить **MPI** и распределённые вычисления.
* Понять масштабирование программы при увеличении количества процессов.
* Научиться делить массив между процессами и собирать результаты с использованием `MPI_Gather`.

**Функционал программы:**

1. Инициализация массива 1 000 000 случайных чисел.
2. Разделение массива на части между процессами.
3. Локальная обработка каждой части (`*2`).
4. Сбор обработанных частей на root-процесс с помощью `MPI_Gather`.
5. Вывод первых и последних 10 элементов исходного и обработанного массива.
6. Замеры времени выполнения для каждого количества процессов.

**Используемые технологии:**

* **C++ / MPI**, `MPI_Init`, `MPI_Comm_rank`, `MPI_Comm_size`, `MPI_Gather`, замеры времени с `std::chrono`.

### Контрольные вопросы (`questions.md`)

Файл содержит ответы на вопросы.
