# HeterogeneousParallelization_Assignment 2

# Assignment 2: OpenMP, CUDA и гетерогенные вычисления

**Astana IT University**  

**Course:** Heterogeneous Parallelization

**Course instructor:** Садвакасова Куралай Жанжигитовна  

**Student:** Жумагулова Карина 

**Group:** ADA-2403M

**Date:** 28.12.2025  

Данный репозиторий содержит решения Assignment 2, посвящённого изучению гетерогенной параллелизации вычислений, а также практическому применению технологий OpenMP и CUDA для ускорения обработки данных.

В рамках работы рассматриваются как теоретические основы гетерогенных вычислений, так и их практическая реализация на примере обработки массивов и алгоритмов сортировки. Особое внимание уделяется сравнению последовательных и параллельных реализаций, анализу производительности и целесообразности использования различных вычислительных архитектур.

В проекте реализованы:
* теоретическое исследование различий между параллельными вычислениями на CPU и GPU;
* работа с массивами в последовательном и параллельном режимах с использованием OpenMP;
* параллельная сортировка выбором на многоядерных процессорах;
* реализация параллельной сортировки слиянием на GPU с использованием CUDA.

Для всех практических заданий проводится измерение времени выполнения, что позволяет наглядно продемонстрировать преимущества и ограничения параллельных вычислений. Работа направлена на формирование понимания того, в каких задачах и при каких условиях гетерогенный подход оказывается наиболее эффективным.

## Структура репозитория

.

├── task_1.md        # Задание 1: теоретическая часть (гетерогенная параллелизация)

├── task_2.cpp       # Задание 2: последовательный и параллельный поиск min/max с OpenMP

├── task_3.cpp       # Задание 3: сортировка выбором (последовательная и параллельная версии)

├── task_4.ipynb     # Задание 4: сортировка слиянием на GPU с использованием CUDA

├── questions.md     # Ответы на контрольные вопросы к Assignment 2

├── README.md        # Общее описание проекта и структура репозитория

### Задание 1 (task1.md)

**Описание**:
Данное задание посвящено теоретическому изучению гетерогенной параллелизации вычислений. В работе рассматриваются принципы распределения задач между CPU и GPU, преимущества такого подхода, а также примеры практического применения.

**Цель задания**:
* Изучить концепцию гетерогенной параллелизации.
* Понять различия между параллельными вычислениями на CPU и GPU.
* Определить преимущества гетерогенного подхода и области его применения.

**Функционал программы/документа**:
* Описание различий архитектур CPU и GPU и их особенностей при параллельной обработке данных.
* Обоснование преимуществ гетерогенной параллелизации, включая ускорение вычислений и оптимальное распределение ресурсов.
* Примеры реальных приложений, использующих гетерогенные вычисления, таких как машинное обучение, научные вычисления и рендеринг графики.

### Задание 2 (task2.cpp)

**Описание:**
Данное задание посвящено практическому изучению **параллельной обработки массивов с использованием OpenMP**. Программа демонстрирует разницу между последовательной и параллельной обработкой данных, а также измеряет влияние параллелизации на время выполнения.

**Цель задания:**

* Создать массив из 10 000 случайных чисел.
* Реализовать поиск **минимального и максимального значений** массива:
  * последовательным способом;
  * с использованием **OpenMP** для параллельной обработки.
* Сравнить время выполнения последовательной и параллельной версий алгоритма и сделать выводы о производительности.

**Функционал программы:**

1. Генерация массива из 10 000 случайных чисел в заданном диапазоне.
2. Последовательный поиск минимального и максимального значения массива с измерением времени.
3. Параллельный поиск минимального и максимального значения массива с использованием OpenMP и измерением времени.
4. Вывод на экран:
   * размер массива;
   * минимальное и максимальное значения;
   * время выполнения для последовательной и параллельной версии.

### Скриншот результатов
<img width="2484" height="1456" alt="image" src="https://github.com/user-attachments/assets/eb364a0c-8ded-4c49-b059-f4935c1cea2e" />

### Задание 3 (task3.cpp)

**Описание:**
Данное задание посвящено **реализации параллельного алгоритма сортировки выбором (Selection Sort) с использованием OpenMP**. Программа демонстрирует разницу между последовательной и параллельной реализацией сортировки и позволяет оценить влияние параллелизации на производительность для массивов разного размера.

**Цель задания:**

* Реализовать **последовательную сортировку выбором** массива.
* Добавить **параллелизм** с помощью директив OpenMP для ускорения работы алгоритма.
* Сравнить производительность последовательной и параллельной версий для массивов размером 1 000 и 10 000 элементов.

**Функционал программы:**

1. Генерация массивов случайных чисел заданного размера (100, 1 000, 10 000, 100 000 элементов).
2. Последовательная сортировка выбором с измерением времени выполнения.
3. Параллельная сортировка выбором с использованием OpenMP с измерением времени выполнения.
4. Вывод на экран:

   * размер массива;
   * время выполнения последовательной и параллельной версии;
   * ускорение параллельной сортировки относительно последовательной.
5. Формулирование выводов о производительности и эффективности параллельного подхода.

### Скриншот результатов
<img width="2484" height="1456" alt="image" src="https://github.com/user-attachments/assets/8b5b8b94-901b-416c-8449-a3b20e262bf5" />


### Задание 4 (`task4.cpp`) — Среднее значение с использованием OpenMP reduction

**Описание:**  
Параллельное вычисление среднего значения массива с использованием **механизма `reduction`**, чтобы безопасно суммировать элементы.  

**Цель задания:**  
* Освоить директиву `reduction` в OpenMP  
* Научиться безопасно выполнять агрегирующие операции в многопоточном коде  

**Файл решения:** task4.cpp

### Контрольные вопросы (`questions.md`)  

Содержит ответы на вопросы по материалам лекций по основам C++ и OpenMP.  

**Файл решения:** questions.md
