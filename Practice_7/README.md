# Практическая работа №7: Редукция и префиксная сумма на GPU

**Astana IT University**

**Курс:** Heterogeneous Parallelization

**Преподаватель:** Садвакасова Куралай Жанжигитовна

**Студент:** Жумагулова Карина

**Группа:** ADA-2403M

**Дата:** 25.01.2026

## Краткое описание практической работы

Данная практическая работа посвящена изучению **параллельных алгоритмов редукции и сканирования (префиксной суммы) на GPU**.

В рамках работы реализованы следующие задачи:

1. **Редукция** — вычисление суммы элементов массива на GPU.
2. **Префиксная сумма** — вычисление накопленной суммы элементов массива на GPU.

Для каждой задачи:

* Реализованы CPU- и GPU-версии.
* Используются **различные типы памяти CUDA**: глобальная и разделяемая (shared memory).
* Проведено сравнение производительности для массивов разного размера.
* Проверена корректность результатов на тестовых данных.

## Цель работы

* Изучить параллельные алгоритмы редукции и сканирования.
* Освоить работу с **CUDA** и различными типами памяти GPU.
* Провести сравнительный анализ производительности CPU и GPU.
* Оптимизировать алгоритмы с использованием shared memory.


## Структура репозитория

```
.
├── task_1.cu  # Реализация редукции (суммирование элементов массива)
├── task_2.cu  # Реализация префиксной суммы (Blelloch Scan)
├── README.md           # Этот файл
```

## Теоретическая часть

### Редукция

Редукция — операция, которая сводит множество элементов к одному значению. В работе реализован **алгоритм параллельной редукции на GPU** с использованием:

* **Параллельного "дерева"** внутри блока.
* **Shared memory** для ускорения доступа.
* Финальная сумма блоков вычисляется на CPU.

### Сканирование (префиксная сумма)

Сканирование — операция, которая вычисляет накопленное значение для каждого элемента массива. Пример:

```
Вход:  [1, 2, 3, 4]
Выход: [1, 3, 6, 10]
```

Реализован **Blelloch Scan** с использованием shared memory для ускорения.

### Типы памяти CUDA

* **Глобальная память** — доступна всем потокам, но медленная.
* **Разделяемая память (shared)** — доступна потокам внутри блока, быстрая.
* **Локальная память** — приватная для каждого потока.


## Практическая часть

### Задача 1: Редукция

#### Реализация

* CPU: последовательная сумма через `std::accumulate`.
* GPU: каждый блок суммирует свою часть массива, внутри блока используется shared memory.
* Размер блока: 256 потоков.

#### Результаты

| N       | CPU time (ms) | GPU time (global) (ms) | GPU time (shared) (ms) | Check   |
| ------- | ------------- | ---------------------- | ---------------------- | ------- |
| 10      | 0.000310      | 0.174720               | 0.098176               | CORRECT |
| 100     | 0.001699      | 0.022560               | 0.050528               | CORRECT |
| 1000    | 0.012678      | 0.059712               | 0.068352               | CORRECT |
| 10000   | 0.133657      | 0.460832               | 0.054976               | CORRECT |
| 100000  | 1.463043      | 17.731873              | 0.116128               | CORRECT |
| 1000000 | 15.774356     | 764.920654             | 0.269792               | CORRECT |

*Вывод*: использование **shared memory** обеспечивает значительное ускорение для больших массивов.

### Задача 2: Префиксная сумма

#### Реализация

* CPU: последовательное суммирование элементов массива.
* GPU: Blelloch Scan на блоках с добавлением смещений блоков.
* Используются **глобальная** и **shared memory**.

#### Результаты (пример для N=10⁶)

```
N = 1000000
CPU time: 9.751153 ms
GPU time (global memory): 779.713684 ms
GPU time (shared memory): 0.242624 ms
Check: Global=CORRECT, Shared=CORRECT
CPU last element: 12494712.000000
GPU (global memory) last element: 12494712.000000
GPU (shared memory) last element: 12494712.000000
```

*Вывод*: алгоритм с **shared memory** работает значительно быстрее и корректно при ограниченном диапазоне значений массива.

### Контрольные вопросы



## Выводы

1. Реализованы параллельные алгоритмы редукции и префиксной суммы на GPU.
2. GPU обеспечивает значительное ускорение при больших массивах.
3. Shared memory дает преимущество в производительности.
4. Результаты GPU совпадают с CPU для корректно выбранных диапазонов значений массива.
