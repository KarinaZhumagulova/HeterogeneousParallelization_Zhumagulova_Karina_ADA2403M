# Контрольные вопросы к Практической работе №7

## 1. В чём разница между редукцией и сканированием?

* **Редукция** – это операция, которая сводит множество элементов массива к **одному значению**.
  Примеры: сумма всех элементов, максимум, минимум, произведение.
  **Пример:** массив `[1, 2, 3, 4]` → редукция по сумме → `10`.

* **Сканирование (префиксная сумма)** – это операция, которая вычисляет накопленный результат **для каждого элемента массива**.
  Примеры: префиксная сумма, префиксное умножение.
  **Пример:** массив `[1, 2, 3, 4]` → сканирование по сумме → `[1, 3, 6, 10]`.

**Главное отличие:**
* Редукция → один результат для всего массива.
* Сканирование → массив того же размера, каждый элемент содержит накопленное значение до этой позиции.

## 2. Какие типы памяти CUDA используются для оптимизации редукции и сканирования?

CUDA предлагает три основных типа памяти:

1. **Глобальная память (Global Memory):**

   * Доступна всем потокам на GPU.
   * Большая, но медленная (относительно разделяемой памяти).

2. **Разделяемая память (Shared Memory):**

   * Доступна только потокам внутри одного блока.
   * Очень быстрая, подходит для редукции и сканирования внутри блока.
   * Позволяет минимизировать обращение к медленной глобальной памяти.

3. **Локальная память (Local Memory):**

   * Выделяется для каждого потока.
   * Фактически, хранится в глобальной памяти, но с приватным доступом для потока.
   * Используется для временных переменных, но медленнее, чем shared memory.

**Вывод:** оптимизация обычно делается за счёт **shared memory**, так как она значительно ускоряет операции редукции и сканирования внутри блока.

## 3. Как можно оптимизировать префиксную сумму на GPU?

Основные подходы:

1. **Использование разделяемой памяти:**

   * Все потоки блока сначала загружают свои данные в shared memory.
   * Затем выполняется сканирование внутри блока (например, алгоритм Blelloch).
   * После этого результаты блока можно объединять в глобальной памяти.

2. **Алгоритм Blelloch (up-sweep / down-sweep):**

   * Up-sweep: строим дерево сумм, пока не получим сумму всего блока.
   * Down-sweep: на основе дерева вычисляем префиксные суммы для всех элементов.
   * Эффективен для больших массивов, позволяет использовать меньше операций синхронизации.

3. **Минимизация обращений к глобальной памяти:**

   * Чтение и запись в глобальную память только один раз (в начале и в конце).
   * Все промежуточные вычисления делаются в shared memory.

4. **Выбор правильного размера блока:**

   * Оптимальный размер блока (обычно кратный warp = 32) повышает производительность.

5. **Использование warp-level примитивов:**

   * CUDA 9+ позволяет использовать функции типа `__shfl_up` для сканирования внутри warp без shared memory.
   * Это снижает накладные расходы на синхронизацию потоков.

## 4. Приведите пример задачи, где применяется сканирование.

Примеры применения префиксной суммы:

1. **Параллельная фильтрация массива:**

   * Нужно удалить элементы, не удовлетворяющие условию.
   * Сканирование позволяет определить новые позиции элементов в выходном массиве.

2. **Построение индексов для структур данных:**

   * Например, для построения CSR (Compressed Sparse Row) формата разреженных матриц.

3. **Параллельное суммирование сегментов (histogram prefix):**

   * Используется в графике и вычислительной геометрии.

4. **Сбор статистики в потоках:**

   * Например, вычисление накопленных вероятностей для алгоритмов типа Monte Carlo или распределений.
