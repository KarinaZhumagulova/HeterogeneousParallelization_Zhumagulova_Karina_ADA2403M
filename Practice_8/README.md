# Практическая работа №8: Гибридная обработка массива на CPU и GPU

**Astana IT University**

**Курс:** Heterogeneous Parallelization

**Преподаватель:** Садвакасова Куралай Жанжигитовна

**Студент:** Жумагулова Карина

**Группа:** ADA-2403M

**Дата:** 25.01.2026

## Краткое описание практической работы

Данная практическая работа посвящена изучению **гибридных вычислений**, при которых задачи распределяются между **CPU** и **GPU** для достижения максимальной производительности.

В рамках работы реализованы следующие задачи:

1. Последовательная обработка массива на CPU.
2. Параллельная обработка массива на CPU с использованием OpenMP.
3. Обработка массива на GPU с использованием CUDA.
4. Гибридная обработка массива: CPU + GPU одновременно.
5. Сравнение производительности всех режимов.

Для каждой задачи:

* Замерено время выполнения.
* Проверена корректность результатов (первые 5 элементов массива до и после обработки).

## Цель работы

* Изучить основы **гибридных вычислений CPU + GPU**.
* Освоить работу с **OpenMP** для многопоточной обработки на CPU.
* Освоить работу с **CUDA** для параллельной обработки на GPU.
* Провести сравнительный анализ производительности разных подходов.
* Научиться эффективно распределять задачи между CPU и GPU и минимизировать накладные расходы на передачу данных.

## Структура репозитория

```
.
├── practice8_all.cu   # Реализация всех режимов (CPU, CPU+OpenMP, CUDA, Hybrid)
├── README.md          # Этот файл
```

## Теоретическая часть

### Гибридные вычисления

Гибридные вычисления — подход, при котором задачи распределяются между CPU и GPU:

* **CPU** используется для последовательных задач и управления данными.
* **GPU** используется для параллельных вычислений с большим числом потоков.

### OpenMP

* API для многопоточного программирования на CPU.
* Позволяет легко распараллеливать циклы и задачи с помощью директив `#pragma omp`.

### CUDA

* Платформа для параллельных вычислений на GPU.
* Позволяет запускать тысячи потоков на видеокарте для обработки массивов данных.

### Передача данных CPU ↔ GPU

* Данные передаются через шину PCI Express.
* Это может стать узким местом в производительности.
* Важно минимизировать количество копирований данных между CPU и GPU.

## Практическая часть

### Задание 1: Последовательная и параллельная обработка на CPU

* Последовательная обработка (`Sequential CPU`) умножает каждый элемент массива на 2.
* Параллельная обработка (`CPU + OpenMP`) делает то же самое с использованием нескольких потоков.
* Замер времени показал:

| Режим          | Время (ms) |
| -------------- | ---------- |
| Sequential CPU | 2.88888    |
| CPU + OpenMP   | 3.73993    |

* Корректность проверена — первые 5 элементов совпадают с ожиданием.

### Задание 2: Обработка массива на GPU (CUDA)

* Данные копируются на GPU, обрабатываются ядром `processGPU`, возвращаются на CPU.
* Время выполнения кернела: **0.092992 ms**.
* Результаты корректны — совпадают с CPU и OpenMP.

### Задание 3: Гибридная обработка CPU + GPU

* Массив делится на две половины:

  * первая половина обрабатывается CPU (OpenMP),
  * вторая половина обрабатывается GPU.
* Замер времени: **1.89634 ms**
* Проверка первых 5 элементов массива — корректно.

### Задание 4: Анализ производительности

| Режим            | Время (ms) |
| ---------------- | ---------- |
| Sequential CPU   | 2.88888    |
| CPU + OpenMP     | 3.73993    |
| CUDA kernel      | 0.092992   |
| Hybrid CPU + GPU | 1.89634    |

**Выводы:**

1. **GPU** значительно ускоряет обработку массивов даже при простой операции.
2. **OpenMP** полезен для сложных вычислений на CPU, но для простой операции накладные расходы на потоки могут превышать выигрыш.
3. **Гибридный подход** эффективно использует ресурсы системы, ускоряя обработку при больших объёмах данных.
4. Эффективность зависит от **баланса данных**, накладных расходов на копирование и сложности вычислений.

**Корректность обработки данных**
   * Все четыре режима обработки массива (Sequential CPU, CPU + OpenMP, CUDA, Hybrid CPU + GPU) дают **идентичные результаты**.
   * Проверка первых элементов массива показала полное совпадение значений, что подтверждает правильную реализацию алгоритма умножения элементов на 2.
   * Это демонстрирует, что параллельные вычисления на CPU и GPU могут быть корректными при правильной синхронизации и управлении памятью.

**Сравнение производительности разных режимов**
   * **Sequential CPU:** 2.88888 ms — базовый вариант, используется один поток, линейное время выполнения.
   * **CPU + OpenMP:** 3.73993 ms — параллельное выполнение на CPU. Накладные расходы на создание потоков для простого умножения превышают выигрыш, поэтому время получилось немного больше.
   * **CUDA kernel:** 0.092992 ms — **резкое ускорение на GPU**, даже с учётом передачи данных. GPU очень эффективен для параллельной обработки больших массивов однотипных операций.
   * **Hybrid CPU + GPU:** 1.89634 ms — объединение ресурсов CPU и GPU позволило снизить общее время почти в два раза по сравнению с последовательным CPU, но накладные расходы на передачу половины массива на GPU увеличивают время по сравнению с чистым CUDA.

**Эффективность гибридного подхода**
   * Гибридная обработка **выигрывает при больших объемах данных**, когда можно эффективно разделить нагрузку между CPU и GPU.
   * Для очень маленьких массивов (например, N < 1000) накладные расходы на копирование данных на GPU и синхронизацию потоков могут сделать гибрид менее эффективным, чем последовательный CPU.
   * В данном эксперименте с массивом на 1 млн элементов гибридный подход показал заметный выигрыш по сравнению с CPU.

**Рекомендации по использованию CPU и GPU**
   * **CPU:** последовательные или ветвящиеся задачи, где параллелизация не даёт существенного выигрыша.
   * **GPU:** однотипные, параллельные задачи с большим количеством данных (например, обработка массивов, векторные операции, матричные вычисления).
   * **Гибридный режим:** лучше использовать для **больших задач**, где можно сбалансировать нагрузку между CPU и GPU. При этом важно минимизировать количество копирований данных между CPU и GPU.

**Влияние накладных расходов на производительность**
   * Для **простых операций** (например, умножение на 2) накладные расходы на OpenMP или копирование на GPU могут быть значительными.
   * Для **сложных вычислений**, где каждый элемент обрабатывается длительное время, GPU и гибридный режим дают гораздо более ощутимый выигрыш.

**Практическая значимость работы**
   * Изучение гибридных вычислений помогает понять, как эффективно использовать ресурсы современных систем с CPU и GPU.
   * Такой подход применим в **обработке больших данных, научных вычислениях, машинном обучении, обработке графики** и других областях, где требуется высокая производительность.

**Вывод по масштабированию**
   * При увеличении размера массива ускорение GPU и гибридного режима по сравнению с CPU растёт почти линейно.
   * Оптимизация количества потоков и блоков CUDA позволяет максимально использовать вычислительные ресурсы GPU.

## Вывод программы

```
Before processing: -61 -75 -12 29 -8 

After Sequential CPU: -122 -150 -24 58 -16 
After CPU + OpenMP: -122 -150 -24 58 -16 
After CUDA: -122 -150 -24 58 -16 
After Hybrid: -122 -150 -24 58 -16 

Sequential CPU time:       2.88888 ms
CPU + OpenMP time:         3.73993 ms
CUDA kernel time:          0.092992 ms
Hybrid CPU + GPU time:     1.89634 ms
```
<img width="1420" height="514" alt="image" src="https://github.com/user-attachments/assets/42b54cc4-b40e-4a6b-bb71-7c0bda9a75ca" />

## Контрольные вопросы
Ответы на контрольные вопросы приведены в файле questions.md.

