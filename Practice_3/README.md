

## Задание 1 (task_1_merge_sort.cu)

**Описание:**
В данном задании реализована **параллельная сортировка слиянием (Merge Sort)** с использованием **CUDA** и **гибридного подхода CPU + GPU**. Массив данных разбивается на подмассивы фиксированного размера, каждый из которых обрабатывается **отдельным блоком потоков GPU**. Внутри каждого блока элементы сортируются параллельно с использованием **shared memory**, после чего отсортированные подмассивы последовательно сливаются на CPU с применением **OpenMP**.

**Цель задания**

* Реализовать **параллельную сортировку слиянием** с использованием **CUDA**.
* Разделить входной массив на блоки, каждый из которых обрабатывается отдельным **CUDA-блоком потоков**.
* Выполнить **параллельную сортировку подмассивов на GPU**.
* Реализовать **параллельное слияние** отсортированных блоков на CPU с использованием **OpenMP**.
* Оценить производительность алгоритма для массивов различного размера.
* Проверить корректность итоговой сортировки.

**Файлы проекта**

* **task_1_merge_sort.cu** — CUDA-программа, реализующая гибридную параллельную сортировку слиянием с использованием GPU и CPU.

**Функционал программы**

1. Генерация массивов случайных целых чисел заданного размера.
2. Разделение массива на подмассивы, соответствующие CUDA-блокам.
3. Параллельная сортировка каждого подмассива на GPU с использованием **shared memory**.
4. Копирование отсортированных блоков с GPU на CPU.
5. Параллельное слияние отсортированных подмассивов методом **Bottom-up Merge Sort** с использованием **OpenMP**.
6. Измерение общего времени выполнения алгоритма.
7. Проверка корректности сортировки и вывод результата.

**Используемые технологии**

* **C++ / CUDA** — реализация параллельных вычислений на GPU.
* **Shared Memory (CUDA)** — ускорение сортировки внутри блоков.
* **OpenMP** — параллельное слияние подмассивов на CPU.
* **std::chrono** — измерение времени выполнения программы.
* **std::random** — генерация случайных данных.

**Особенности реализации**

* Каждый **CUDA-блок** обрабатывает отдельный подмассив фиксированного размера.
* Для локальной сортировки используется **Insertion Sort**, оптимальный для небольших массивов в shared memory.
* Слияние подмассивов выполняется поэтапно с удвоением размера блоков (итеративный Merge Sort).
* Реализация демонстрирует **гибридный подход** к параллельным вычислениям с использованием ресурсов **GPU и CPU**.
* Алгоритм масштабируется для массивов от сотен до миллионов элементов.

**Назначение задания**

Выполнение данного задания позволяет:

* Освоить основы **параллельной сортировки на GPU**.
* Изучить работу **CUDA-блоков, потоков и shared memory**.
* Понять принципы **гибридных вычислений (CPU + GPU)**.
* Сравнить эффективность различных этапов параллельной обработки данных.
* Получить практический опыт реализации **параллельных алгоритмов сортировки**.


