# Практическая работа №3: Реализация сложных алгоритмов сортировки на GPU с использованием CUDA

**Astana IT University**  

**Курс:** Heterogeneous Parallelization  

**Преподаватель:** Садвакасова Куралай Жанжигитовна  

**Студент:** Жумагулова Карина  

**Группа:** ADA-2403M  

**Дата:** 28.12.2025  

Данный репозиторий содержит решения практической работы №3, посвящённой реализации **сложных алгоритмов сортировки** (слияние, быстрая, пирамидальная) с использованием **GPU и CUDA**.  

В работе изучены следующие аспекты:
- Основы программирования на CUDA и организация параллельных вычислений на GPU.
- Реализация и оптимизация сложных алгоритмов сортировки на GPU.
- Сравнение производительности алгоритмов на GPU и CPU для массивов разного размера.

## Цель работы

- Освоить основы параллельного программирования на GPU с использованием CUDA.  
- Реализовать и оптимизировать сложные алгоритмы сортировки: **Merge Sort, Quick Sort, Heap Sort**.  
- Сравнить производительность реализаций на GPU и CPU для массивов различного объёма.  

## Теоретическая часть

### Основные алгоритмы сортировки

1. **Сортировка слиянием (Merge Sort)**  
   - Алгоритм "разделяй и властвуй": массив делится на части, сортируются и затем сливаются.  
   - Время выполнения: O(n log n).  

2. **Быстрая сортировка (Quick Sort)**  
   - Выбирается опорный элемент (pivot), массив разделяется на элементы меньше и больше pivot, затем рекурсивно сортируются части.  
   - Среднее время выполнения: O(n log n), худшее: O(n²).  

3. **Пирамидальная сортировка (Heap Sort)**  
   - Строится бинарная куча, наибольший элемент извлекается и куча перестраивается.  
   - Время выполнения: O(n log n).  

### Программирование на CUDA

CUDA позволяет организовывать **параллельные вычисления на GPU**, используя тысячи потоков.  
В этой работе используются:
- **Индексация потоков**: каждый поток обрабатывает часть массива.  
- **Разделяемая память блоков**: ускоряет взаимодействие потоков внутри блока.  
- **Функции управления памятью**: `cudaMalloc`, `cudaMemcpy`, `cudaFree` — для выделения, копирования и освобождения памяти на GPU.  



## Практическая часть


## Структура репозитория
.

├── task_1_merge_sort.cu       # Параллельная сортировка слиянием на GPU

├── task_2_quick_sort_v1.cu    # Параллельная быстрая сортировка на GPU

├── task_2_quick_sort_v2.cu    # Параллельная быстрая сортировка на GPU

├── task_3_heap_sort.cu        # Параллельная пирамидальная сортировка на GPU

├── task_4_cpu_sorts.cpp       # Последовательные версии сортировок на CPU

├── questions.md               # Контрольные вопросы и ответы по работе

├── README.md                  # Описание проекта



---

## Результаты

- Для каждого алгоритма приведены измерения времени выполнения на CPU и GPU.  
- Сравнена эффективность параллельной реализации с последовательной для массивов разного размера.  

---

## Выводы

- CUDA позволяет значительно ускорить выполнение сортировок на больших массивах.  
- На малых массивах GPU может уступать CPU из-за накладных расходов на передачу данных.  
- На больших массивах наблюдается **существенное преимущество параллельных реализаций**.  
```

---

Если хочешь, я могу сделать **ещё более красивую версию README с таблицами производительности**, где сразу будет видно, сколько миллисекунд занимает каждая сортировка на GPU и CPU для разных размеров массивов.

Хочешь, чтобы я это сделал?



## Задание 1 (task_1_merge_sort.cu)

**Описание:**
В данном задании реализована **параллельная сортировка слиянием (Merge Sort)** с использованием **CUDA** и **гибридного подхода CPU + GPU**. Массив данных разбивается на подмассивы фиксированного размера, каждый из которых обрабатывается **отдельным блоком потоков GPU**. Внутри каждого блока элементы сортируются параллельно с использованием **shared memory**, после чего отсортированные подмассивы последовательно сливаются на CPU с применением **OpenMP**.

**Цель задания**

* Реализовать **параллельную сортировку слиянием** с использованием **CUDA**.
* Разделить входной массив на блоки, каждый из которых обрабатывается отдельным **CUDA-блоком потоков**.
* Выполнить **параллельную сортировку подмассивов на GPU**.
* Реализовать **параллельное слияние** отсортированных блоков на CPU с использованием **OpenMP**.
* Оценить производительность алгоритма для массивов различного размера.
* Проверить корректность итоговой сортировки.

**Файлы проекта**

* **task_1_merge_sort.cu** — CUDA-программа, реализующая гибридную параллельную сортировку слиянием с использованием GPU и CPU.

**Функционал программы**

1. Генерация массивов случайных целых чисел заданного размера.
2. Разделение массива на подмассивы, соответствующие CUDA-блокам.
3. Параллельная сортировка каждого подмассива на GPU с использованием **shared memory**.
4. Копирование отсортированных блоков с GPU на CPU.
5. Параллельное слияние отсортированных подмассивов методом **Bottom-up Merge Sort** с использованием **OpenMP**.
6. Измерение общего времени выполнения алгоритма.
7. Проверка корректности сортировки и вывод результата.

**Используемые технологии**

* **C++ / CUDA** — реализация параллельных вычислений на GPU.
* **Shared Memory (CUDA)** — ускорение сортировки внутри блоков.
* **OpenMP** — параллельное слияние подмассивов на CPU.
* **std::chrono** — измерение времени выполнения программы.
* **std::random** — генерация случайных данных.

**Особенности реализации**

* Каждый **CUDA-блок** обрабатывает отдельный подмассив фиксированного размера.
* Для локальной сортировки используется **Insertion Sort**, оптимальный для небольших массивов в shared memory.
* Слияние подмассивов выполняется поэтапно с удвоением размера блоков (итеративный Merge Sort).
* Реализация демонстрирует **гибридный подход** к параллельным вычислениям с использованием ресурсов **GPU и CPU**.
* Алгоритм масштабируется для массивов от сотен до миллионов элементов.

**Назначение задания**

Выполнение данного задания позволяет:

* Освоить основы **параллельной сортировки на GPU**.
* Изучить работу **CUDA-блоков, потоков и shared memory**.
* Понять принципы **гибридных вычислений (CPU + GPU)**.
* Сравнить эффективность различных этапов параллельной обработки данных.
* Получить практический опыт реализации **параллельных алгоритмов сортировки**.

### Скриншот результатов
<img width="1838" height="1108" alt="image" src="https://github.com/user-attachments/assets/ab419162-edcf-4a10-90fc-11f732ad82b9" />

## Контрольные вопросы (`questions.md`)

- Вопросы и ответы по теории алгоритмов сортировки и OpenMP.  
- Включает анализ преимуществ и недостатков параллельной реализации.

## Используемые технологии
В рамках Practice 2 были использованы следующие технологии:
- **C++ (стандарт C++17)**;
- **OpenMP** для реализации параллельных вычислений;
- **`<chrono>`** для измерения времени выполнения алгоритмов.

## Выводы
По результатам практической работы:
- реализованы и протестированы последовательные и параллельные алгоритмы сортировки;
- показано, что параллельные версии эффективны в основном для массивов большого размера;
- получен практический опыт использования OpenMP и анализа производительности программ.



