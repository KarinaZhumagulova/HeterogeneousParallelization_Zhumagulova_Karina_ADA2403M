# Практическая работа №3: Реализация сложных алгоритмов сортировки на GPU с использованием CUDA

**Astana IT University**  

**Курс:** Heterogeneous Parallelization  

**Преподаватель:** Садвакасова Куралай Жанжигитовна  

**Студент:** Жумагулова Карина  

**Группа:** ADA-2403M  

**Дата:** 28.12.2025  

Данный репозиторий содержит решения практической работы №3, посвящённой реализации **сложных алгоритмов сортировки** (слияние, быстрая, пирамидальная) с использованием **GPU и CUDA**.  

В работе изучены следующие аспекты:
- Основы программирования на CUDA и организация параллельных вычислений на GPU.
- Реализация и оптимизация сложных алгоритмов сортировки на GPU.
- Сравнение производительности алгоритмов на GPU и CPU для массивов разного размера.

## Цель работы

- Освоить основы параллельного программирования на GPU с использованием CUDA.  
- Реализовать и оптимизировать сложные алгоритмы сортировки: **Merge Sort, Quick Sort, Heap Sort**.  
- Сравнить производительность реализаций на GPU и CPU для массивов различного объёма.  

## Теоретическая часть

### Основные алгоритмы сортировки

1. **Сортировка слиянием (Merge Sort)**  
   - Алгоритм "разделяй и властвуй": массив делится на части, сортируются и затем сливаются.  
   - Время выполнения: O(n log n).  

2. **Быстрая сортировка (Quick Sort)**  
   - Выбирается опорный элемент (pivot), массив разделяется на элементы меньше и больше pivot, затем рекурсивно сортируются части.  
   - Среднее время выполнения: O(n log n), худшее: O(n²).  

3. **Пирамидальная сортировка (Heap Sort)**  
   - Строится бинарная куча, наибольший элемент извлекается и куча перестраивается.  
   - Время выполнения: O(n log n).  

### Программирование на CUDA

CUDA позволяет организовывать **параллельные вычисления на GPU**, используя тысячи потоков.  
В этой работе используются:
- **Индексация потоков**: каждый поток обрабатывает часть массива.  
- **Разделяемая память блоков**: ускоряет взаимодействие потоков внутри блока.  
- **Функции управления памятью**: `cudaMalloc`, `cudaMemcpy`, `cudaFree` — для выделения, копирования и освобождения памяти на GPU.  



## Практическая часть


## Структура репозитория
.

├── task_1_merge_sort.cu       # Параллельная сортировка слиянием на GPU

├── task_2_quick_sort_v1.cu    # Параллельная быстрая сортировка на GPU

├── task_2_quick_sort_v2.cu    # Параллельная быстрая сортировка на GPU

├── task_3_heap_sort.cu        # Параллельная пирамидальная сортировка на GPU

├── task_4_cpu_sorts.cpp       # Последовательные версии сортировок на CPU

├── questions.md               # Контрольные вопросы и ответы по работе

├── README.md                  # Описание проекта


## Задание 1 (task_1_merge_sort.cu)

**Описание:**
В данном задании реализована **параллельная сортировка слиянием (Merge Sort)** с использованием **CUDA** и **гибридного подхода CPU + GPU**. Массив данных разбивается на подмассивы фиксированного размера, каждый из которых обрабатывается **отдельным блоком потоков GPU**. Внутри каждого блока элементы сортируются параллельно с использованием **shared memory**, после чего отсортированные подмассивы последовательно сливаются на CPU с применением **OpenMP**.

**Цель задания**

* Реализовать **параллельную сортировку слиянием** с использованием **CUDA**.
* Разделить входной массив на блоки, каждый из которых обрабатывается отдельным **CUDA-блоком потоков**.
* Выполнить **параллельную сортировку подмассивов на GPU**.
* Реализовать **параллельное слияние** отсортированных блоков на CPU с использованием **OpenMP**.
* Оценить производительность алгоритма для массивов различного размера.
* Проверить корректность итоговой сортировки.

**Файлы проекта**

* **task_1_merge_sort.cu** — CUDA-программа, реализующая гибридную параллельную сортировку слиянием с использованием GPU и CPU.

**Функционал программы**

1. Генерация массивов случайных целых чисел заданного размера.
2. Разделение массива на подмассивы, соответствующие CUDA-блокам.
3. Параллельная сортировка каждого подмассива на GPU с использованием **shared memory**.
4. Копирование отсортированных блоков с GPU на CPU.
5. Параллельное слияние отсортированных подмассивов методом **Bottom-up Merge Sort** с использованием **OpenMP**.
6. Измерение общего времени выполнения алгоритма.
7. Проверка корректности сортировки и вывод результата.

**Используемые технологии**

* **C++ / CUDA** — реализация параллельных вычислений на GPU.
* **Shared Memory (CUDA)** — ускорение сортировки внутри блоков.
* **OpenMP** — параллельное слияние подмассивов на CPU.
* **std::chrono** — измерение времени выполнения программы.
* **std::random** — генерация случайных данных.

**Особенности реализации**

* Каждый **CUDA-блок** обрабатывает отдельный подмассив фиксированного размера.
* Для локальной сортировки используется **Insertion Sort**, оптимальный для небольших массивов в shared memory.
* Слияние подмассивов выполняется поэтапно с удвоением размера блоков (итеративный Merge Sort).
* Реализация демонстрирует **гибридный подход** к параллельным вычислениям с использованием ресурсов **GPU и CPU**.
* Алгоритм масштабируется для массивов от сотен до миллионов элементов.

**Назначение задания**

Выполнение данного задания позволяет:

* Освоить основы **параллельной сортировки на GPU**.
* Изучить работу **CUDA-блоков, потоков и shared memory**.
* Понять принципы **гибридных вычислений (CPU + GPU)**.
* Сравнить эффективность различных этапов параллельной обработки данных.
* Получить практический опыт реализации **параллельных алгоритмов сортировки**.

### Скриншот результатов
<img width="1838" height="1108" alt="image" src="https://github.com/user-attachments/assets/ab419162-edcf-4a10-90fc-11f732ad82b9" />

## Задание 2 (task_2_quick_sort_v1.cu)

**Описание:**
В данном задании реализована **параллельная быстрая сортировка (Quick Sort)** с использованием **CUDA**. Массив данных разделяется на блоки, каждый из которых обрабатывается отдельным **потоком GPU**. Для каждого потока выполняется **итеративная версия Quick Sort** на своей части массива. После завершения параллельной сортировки на GPU выполняется финальная глобальная сортировка на CPU с использованием стандартного алгоритма `std::sort` для корректного объединения всех частей.

**Цель задания**

* Освоить **параллельное программирование на GPU** с использованием CUDA.
* Реализовать **быструю сортировку** для части массива на уровне каждого потока GPU.
* Обеспечить корректное объединение результатов с помощью **финальной сортировки на CPU**.
* Измерить производительность алгоритма на массивах различного размера и сравнить с последовательной реализацией.
* Проверить корректность итоговой сортировки.

**Файлы проекта**

* **task_2_quick_sort_v1.cu** — CUDA-программа, реализующая параллельную быструю сортировку с использованием потоков GPU.

**Функционал программы**

1. Генерация массивов случайных чисел заданного размера с использованием `std::random`.
2. Разделение массива на блоки по количеству потоков GPU.
3. Параллельная сортировка каждого блока с использованием **итеративного Quick Sort** внутри каждого потока CUDA.
4. Копирование отсортированных блоков с GPU на CPU (`cudaMemcpy`).
5. Финальная глобальная сортировка всего массива на CPU с помощью `std::sort`.
6. Измерение времени выполнения всего процесса сортировки с использованием `std::chrono`.
7. Проверка корректности сортировки и вывод первых/последних 10 элементов массива.

**Используемые технологии**

* **C++ / CUDA** — реализация параллельных вычислений на GPU.
* **OpenMP** — параллельная генерация случайных чисел.
* **std::chrono** — измерение времени выполнения программы.
* **std::random** — генерация случайных чисел.
* **std::sort** — финальная глобальная сортировка на CPU.

**Особенности реализации**

* Каждый поток GPU обрабатывает отдельный подмассив, вычисляя свои границы (`items_per_thread`).
* Итеративная версия Quick Sort позволяет сортировать массив без глубокой рекурсии на GPU.
* Используется финальная сортировка на CPU для объединения результатов всех потоков и обеспечения корректности.
* Программа масштабируется для массивов от сотен до миллионов элементов.
* Демонстрируется подход **гибридной сортировки**, где GPU обрабатывает локальные подмассивы, а CPU объединяет результат.

**Назначение задания**

Выполнение данного задания позволяет:

* Освоить принципы **параллельной быстрой сортировки на GPU**.
* Изучить взаимодействие **GPU и CPU при обработке больших массивов**.
* Понять, как **делить работу между потоками GPU** и управлять памятью с помощью `cudaMalloc` и `cudaMemcpy`.
* Сравнить эффективность параллельной сортировки с последовательной реализацией на CPU.

### Скриншот результатов
<img width="1838" height="1108" alt="image" src="https://github.com/user-attachments/assets/d84d6a35-2ae1-428f-905b-1250848573fd" />

## Задание 2 (task_2_quick_sort_v2.cu)

**Описание:**
В данном задании реализована **гибридная быстрая сортировка (Quick Sort)** с использованием **CUDA и CPU**. Алгоритм сочетает **подсчёт элементов на GPU** и **рекурсивное разбиение и сортировку на CPU**. CUDA-ядро выполняет подсчёт количества элементов меньших опорного, после чего CPU выполняет **разбиение массива и рекурсивную сортировку** для каждой части. Такой подход позволяет эффективно использовать GPU для параллельной работы с данными и CPU для рекурсивных операций.

**Цель задания**

* Освоить **гибридное параллельное программирование (GPU + CPU)**.
* Реализовать **Quick Sort с использованием CUDA** для подсчёта элементов и CPU для рекурсивного разбиения массива.
* Измерить производительность алгоритма на массивах различного размера.
* Проверить корректность итоговой сортировки.

**Файлы проекта**

* **task_2_quick_sort_v2.cu** — CUDA-программа, реализующая гибридную быструю сортировку с подсчётом элементов на GPU и рекурсией на CPU.

**Функционал программы**

1. Генерация массивов случайных чисел заданного размера с использованием `std::random`.
2. Выбор опорного элемента для сегмента массива.
3. Параллельный подсчёт элементов меньших опорного на GPU с использованием CUDA-ядра (`atomicAdd`).
4. Разбиение массива и перестановка элементов на CPU.
5. Рекурсивная сортировка левой и правой части массива на CPU.
6. Измерение времени выполнения всего процесса сортировки с использованием `std::chrono`.
7. Вывод первых и последних 10 элементов массива до и после сортировки.
8. Проверка корректности сортировки.

**Используемые технологии**

* **C++ / CUDA** — реализация параллельных вычислений на GPU.
* **atomicAdd (CUDA)** — безопасный подсчёт элементов меньших опорного.
* **std::chrono** — измерение времени выполнения программы.
* **std::random** — генерация случайных чисел.
* **std::vector** — хранение и работа с динамическими массивами.

**Особенности реализации**

* GPU используется только для **подсчёта элементов меньших опорного**, что позволяет ускорить локальные вычисления.
* Разбиение массива и рекурсия выполняются на CPU для упрощения управления памятью и рекурсией.
* Гибридный подход демонстрирует **эффективное сочетание GPU и CPU** для сортировки больших массивов.
* Программа масштабируется для массивов от сотен до миллионов элементов.

**Назначение задания**

Выполнение данного задания позволяет:

* Освоить **гибридное использование GPU и CPU** для алгоритмов сортировки.
* Изучить взаимодействие **CUDA-ядра и CPU** при обработке больших массивов.
* Понять принцип работы **атомарных операций** на GPU (`atomicAdd`).
* Сравнить эффективность параллельной обработки на GPU и последовательной рекурсии на CPU.

### Скриншот результатов
<img width="1838" height="1048" alt="image" src="https://github.com/user-attachments/assets/83c28df0-4750-478e-b926-e46b8e46c98c" />

## Задание 3 (task_3_heap_sort.cu)

**Описание:**
В данном задании реализована **гибридная параллельная сортировка кучей (Heap Sort)** с использованием **GPU и CPU**. Алгоритм строит **локальные кучи на GPU** для блоков массива, после чего выполняется **окончательная сортировка на CPU**, объединяя результаты всех локальных куч. Такой подход позволяет ускорить подготовительный этап сортировки с использованием параллельных возможностей GPU, а затем завершить сортировку эффективно на CPU.

**Цель задания**

* Освоить **гибридное использование GPU и CPU** для реализации алгоритмов сортировки.
* Реализовать **Heap Sort с локальными кучами на GPU** и окончательным упорядочиванием на CPU.
* Измерить производительность алгоритма на массивах различного размера.
* Проверить корректность итоговой сортировки.

**Файлы проекта**

* **task_3_heap_sort.cu** — CUDA-программа, реализующая гибридную параллельную сортировку кучей с локальными кучами на GPU и окончательной сортировкой на CPU.

**Функционал программы**

1. Генерация массивов случайных чисел заданного размера с использованием `std::random`.
2. Параллельное построение **локальных кучи** в блоках массива на GPU с помощью CUDA-ядра `heapify_block`.
3. Копирование частично обработанного массива обратно на CPU.
4. Полная сортировка массива на CPU с использованием классического **Heap Sort** (`heapSort_cpu`).
5. Измерение времени выполнения всего процесса сортировки с использованием `std::chrono`.
6. Вывод первых и последних 10 элементов массива до и после сортировки.
7. Проверка корректности сортировки.

**Используемые технологии**

* **C++ / CUDA** — реализация параллельных вычислений на GPU.
* **std::vector** — работа с динамическими массивами.
* **std::random** — генерация случайных чисел.
* **std::chrono** — измерение времени выполнения программы.
* **std::swap** — перестановка элементов при heapify и сортировке.

**Особенности реализации**

* GPU используется для **построения локальных куч** в блоках массива, ускоряя подготовительный этап.
* CPU выполняет **окончательную сортировку**, объединяя результаты локальных куч.
* Гибридный подход демонстрирует **эффективное сочетание GPU и CPU** для сортировки больших массивов.
* Программа масштабируется для массивов от сотен до миллионов элементов.

**Назначение задания**

Выполнение данного задания позволяет:

* Освоить принципы **гибридного параллельного программирования (GPU + CPU)**.
* Изучить работу **локальных куч на GPU** и их интеграцию с CPU.
* Понять механизмы **Heap Sort** и их оптимизацию с использованием блоков GPU.
* Сравнить эффективность параллельной обработки на GPU и последовательной сортировки на CPU.

### Скриншот результатов
<img width="1838" height="1048" alt="image" src="https://github.com/user-attachments/assets/9bb8a173-8765-4c4f-b7fa-99449228fae0" />

## Задание 4 (task_4_cpu_sorts.cpp)

**Описание:**
В этом задании реализованы **последовательные и параллельные алгоритмы сортировки** на CPU с использованием **C++ и OpenMP**. Алгоритмы включают **Merge Sort, Quick Sort и Heap Sort**. Параллельные версии используют возможности многопоточности OpenMP для ускорения сортировки больших массивов.

**Цель задания**

* Изучить реализацию классических алгоритмов сортировки на CPU.
* Освоить **параллельное программирование с OpenMP** для рекурсивных алгоритмов.
* Сравнить **время выполнения последовательных и параллельных версий** сортировок на разных размерах массивов.
* Проверить корректность сортировки после выполнения алгоритмов.

**Файлы проекта**

* **task_4_cpu_sorts.cpp** — C++ программа для тестирования последовательных и параллельных сортировок.

**Функционал программы**

1. Генерация массивов случайных чисел заданного размера с использованием `std::random`.
2. Последовательные алгоритмы сортировки:

   * **Merge Sort** — рекурсивное деление массива и слияние отсортированных подмассивов.
   * **Quick Sort** — рекурсивное разбиение массива относительно опорного элемента.
   * **Heap Sort** — построение max-кучи и последовательное извлечение элементов.
3. Параллельные алгоритмы с OpenMP:

   * **Merge Sort Parallel** — разделение рекурсии на секции OpenMP с ограничением глубины параллелизма.
   * **Quick Sort Parallel** — аналогично, рекурсивная параллельная сортировка.
   * **Heap Sort Parallel** — параллельное построение кучи, последовательное извлечение элементов.
4. Измерение времени выполнения сортировок с использованием `std::chrono`.
5. Вывод информации о результатах сортировки:

   * Время выполнения в миллисекундах.
   * Проверка, отсортирован ли массив корректно.

**Особенности реализации**

* **Гибрид последовательного и параллельного подхода** для рекурсивных алгоритмов с ограничением глубины параллелизма (по умолчанию 4 уровня).
* Heap Sort реализован с возможностью **параллельного heapify**, ускоряя подготовку кучи.
* Программа тестирует массивы различного размера: от 100 до 1 000 000 элементов.
* Лямбда-функции используются для удобного измерения производительности алгоритмов.

**Используемые технологии**

* **C++17 / OpenMP** — многопоточность на CPU.
* **std::vector / динамические массивы** — управление памятью.
* **std::random / mt19937** — генерация случайных чисел.
* **std::chrono** — измерение времени выполнения сортировок.

**Назначение задания**

Выполнение данного задания позволяет:

* Сравнить **эффективность последовательных и параллельных сортировок**.
* Понять принципы **рекурсивного деления массивов** и их объединения.
* На практике освоить **параллельную обработку массивов с OpenMP**.
* Провести анализ **масштабируемости алгоритмов на CPU** при увеличении размера массива.

### Скриншот результатов
<img width="1502" height="1026" alt="image" src="https://github.com/user-attachments/assets/2a080e56-4b96-4ec6-8161-7d7d3fc2102e" />

## Контрольные вопросы (`questions.md`)

- Краткие вопросы и ответы по теории последовательной и параллельной сортировки (Merge, Quick, Heap).
- Рассматривается использование OpenMP и CUDA, влияние потоков и блоков на производительность.
- Обсуждаются особенности реализации алгоритмов на GPU, синхронизация, разделяемая память и оптимальный выбор параметров блоков и потоков.
- Анализируются преимущества и ограничения параллельной сортировки для разных размеров массивов.


## Выводы
По результатам практической работы:
- Были реализованы и протестированы последовательные и параллельные версии алгоритмов сортировки: Merge Sort, Quick Sort, Heap Sort.
- Параллельные реализации с использованием OpenMP (CPU) и CUDA (GPU) показали значительное ускорение на больших массивах данных по сравнению с последовательными.
- Эффективность параллельной сортировки зависит от размера массива, количества потоков, структуры данных и выбора параметров блоков и потоков на GPU.
- Для небольших массивов параллельная сортировка может быть менее эффективной из-за накладных расходов на синхронизацию и распределение потоков.
- Гибридные подходы, сочетающие GPU для локальных вычислений и CPU для окончательной обработки (например, в Heap Sort и Quick Sort), позволяют оптимизировать время выполнения.
- Работа закрепила знания о параллельном программировании, управлении памятью на GPU, синхронизации потоков и анализе производительности алгоритмов.

## Сравнение производительности

### Таблица времени сортировки (в мс)

| Алгоритм   | Размер массива | CPU Seq  | CPU Parallel | GPU Seq  |
| ---------- | -------------- | -------- | ------------ | -------- |
| Merge Sort | 100            | 0.353    | 3.991        | 43.639   |
| Quick Sort | 100            | 0.011    | 1.378        | 114.482  |
| Heap Sort  | 100            | 0.017    | 15.219       | 119.579  |
| Merge Sort | 1,000          | 5.876    | 2.554        | 0.132    |
| Quick Sort | 1,000          | 0.127    | 0.727        | 81.341   |
| Heap Sort  | 1,000          | 1.142    | 7.310        | 0.715    |
| Merge Sort | 10,000         | 439.486  | 20.806       | 1.159    |
| Quick Sort | 10,000         | 6.556    | 12.465       | 799.137  |
| Heap Sort  | 10,000         | 14.401   | 6.558        | 5.138    |
| Merge Sort | 100,000        | 527.757  | 175.559      | 13.608   |
| Quick Sort | 100,000        | 67.820   | 47.409       | 8,158.66 |
| Heap Sort  | 100,000        | 105.325  | 119.297      | 54.796   |
| Merge Sort | 1,000,000      | 3,167.3  | 1,529.02     | 183.783  |
| Quick Sort | 1,000,000      | 1,529.63 | 1,782.22     | 100,550  |
| Heap Sort  | 1,000,000      | 634.77   | 707.541      | 695.72   |


### Выводы по производительности

1. **Последовательные CPU алгоритмы**:

   * Quick Sort быстрее всего на маленьких массивах.
   * Merge Sort на больших массивах значительно медленнее, особенно на миллионах элементов.
   * Heap Sort стабилен, но чуть медленнее Quick Sort на средних массивах.

2. **Параллельные CPU алгоритмы (OpenMP)**:

   * На небольших массивах (100–1,000) параллельные версии могут быть **медленнее**, чем последовательные, из-за накладных расходов на создание потоков.
   * На больших массивах (10,000 и более) параллельные Merge и Quick Sort показывают значительное ускорение.
   * Параллельный Heap Sort не корректно работает на всех размерах (ошибка сортировки).

3. **GPU алгоритмы (CUDA)**:

   * Merge Sort на GPU очень эффективен на больших массивах (1,000–1,000,000).
   * Quick Sort на GPU корректно работает, но медленнее на малых и средних массивах из-за накладных расходов на распределение потоков.
   * Heap Sort на GPU корректно работает и быстрее последовательного CPU Heap Sort на больших массивах.

4. **Общие тенденции**:

   * **Параллелизация выгодна только на больших массивах**; на маленьких массивов накладные расходы перевешивают.
   * GPU эффективно обрабатывает большие массивы, особенно Merge Sort.
   * Quick Sort и Heap Sort на GPU на маленьких массивах могут быть медленнее CPU.
   * Параллельная реализация Heap Sort на CPU пока нестабильна (ошибка сортировки).
