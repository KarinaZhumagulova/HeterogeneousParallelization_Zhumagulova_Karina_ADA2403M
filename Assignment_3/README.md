# HeterogeneousParallelization_Assignment 3

# Assignment 3: Архитектура GPU и оптимизация CUDA-программ

**Astana IT University**  

**Course:** Heterogeneous Parallelization

**Course instructor:** Садвакасова Куралай Жанжигитовна  

**Student:** Жумагулова Карина 

**Group:** ADA-2403M

**Date:** 18.01.2026  

Данный репозиторий содержит решения Assignment 3, посвящённого изучению архитектуры GPU и оптимизации программ на CUDA. Работа демонстрирует принципы гетерогенной параллелизации с использованием GPU, исследует типы памяти в архитектуре CUDA и изучает, как различные конфигурации потоков и блоков влияют на производительность.

Основное внимание уделяется:
- Пониманию и использованию иерархии памяти GPU для ускорения вычислений.
- Реализации CUDA-ядр с использованием глобальной и разделяемой памяти.
- Анализу эффекта шаблонов доступа к памяти: коалесцированного и некоалесцированного.
- Подбору оптимальной конфигурации сетки и блоков потоков для максимальной производительности.
- Измерению ускорения и сравнению результатов оптимизированной и неоптимизированной версии программы.

## Структура репозитория

.
.
├── HP_Assignment_3.ipynb  # Все 4 задания
├── task_1.cu              # Задание 1: поэлементная обработка массива (глобальная vs shared память)
├── task_2.cu              # Задание 2: поэлементное сложение массивов с разными размерами блоков
├── task_3.cu              # Задание 3: коалесцированный vs некоалесцированный доступ к памяти
├── task_4.cu              # Задание 4: подбор оптимальной конфигурации сетки и блоков
├── questions.md           # Ответы на контрольные вопросы Assignment 3
├── README.md              # Описание проекта и структура репозитория

## Задание 1 (task1.cu)

**Описание:**
Данное задание посвящено изучению **типов памяти GPU** и их влияния на производительность CUDA-программ. Программа выполняет поэлементное умножение массива чисел на константу двумя способами:

1. Используя **глобальную память** (global memory) GPU.
2. Используя **разделяемую память** (shared memory) внутри блока потоков.

Программа сравнивает время выполнения обеих версий, демонстрируя преимущества быстрого доступа к разделяемой памяти.

**Цель задания:**

* Изучить работу **глобальной и shared памяти** на GPU.
* Оценить влияние типа памяти на производительность ядра CUDA.
* Научиться измерять время выполнения GPU-ядр с помощью **cudaEvent_t**.
* Рассмотреть подходы к оптимизации CUDA-программ через использование shared memory.

**Функционал программы:**

1. **Инициализация данных:**

   * Генерация массива из 1 000 000 случайных чисел.
   * Выделение памяти на CPU (RAM) и GPU (VRAM).

2. **Глобальная память (Global Memory):**

   * Копирование массива на GPU.
   * Запуск ядра `multiply_global`, которое умножает каждый элемент массива на константу, используя **только глобальную память**.
   * Синхронизация потоков, замер времени выполнения, копирование результата обратно на CPU.
   * Вывод первых и последних 5 элементов массива для проверки корректности.

3. **Разделяемая память (Shared Memory):**

   * Копирование массива на GPU.
   * Запуск ядра `multiply_shared`, которое использует **shared memory** внутри блока для ускорения операций.
   * Синхронизация потоков, замер времени выполнения, копирование результата обратно на CPU.
   * Вывод первых и последних 5 элементов массива.

4. **Анализ производительности:**

   * Сравнение времени выполнения двух версий ядра.
   * Расчет **коэффициента ускорения (speedup)**: `time_global / time_shared`.
   * Вывод результатов на экран.

**Используемые технологии:**

* **C++ / CUDA** — реализация ядра на GPU.
* **Global memory** — основной тип памяти GPU, медленный доступ.
* **Shared memory** — память внутри блока, более быстрая, позволяет ускорять вычисления.
* **cudaEvent_t** — измерение времени работы GPU-ядр.
* **std::random / Mersenne Twister** — генерация случайных чисел.

**Применение:**

* Изучение **эффективного использования памяти GPU**.
* Демонстрация **преимущества shared memory** для ускорения вычислений.
* Освоение методики **замера времени выполнения CUDA-ядр** и оценки ускорения.

## Задание 2 (task2.cu)

**Описание:**
Данное задание посвящено изучению **влияния размера блока потоков (threads per block) на производительность CUDA-программы**. Программа выполняет поэлементное **сложение двух массивов** на GPU и позволяет наглядно увидеть, как выбор конфигурации сетки и блока потоков влияет на скорость выполнения ядра.

**Цель задания:**

* Реализовать CUDA-программу для **поэлементного сложения массивов**.
* Исследовать влияние **размера блока потоков** на производительность.
* Научиться измерять **время выполнения GPU-ядра** для различных параметров сетки и блоков.
* Сформировать представление о том, как оптимизация конфигурации блоков и сетки может ускорить параллельные вычисления на GPU.

**Функционал программы:**

1. **Инициализация данных:**

   * Генерация двух массивов `A` и `B` длиной 1 000 000 элементов.
   * Выделение памяти на CPU (RAM) и GPU (VRAM).

2. **Запуск ядра сложения (Vector Add):**

   * Для каждого размера блока (`32, 64, 128, 256, 512`) рассчитывается количество блоков сетки.
   * Каждый поток GPU складывает один элемент массивов `A` и `B` и записывает результат в массив `C`.

3. **Замер времени выполнения:**

   * Используются **cudaEvent_t** для точного измерения времени работы ядра.
   * Копирование результатов обратно на CPU для проверки корректности.

4. **Вывод результатов:**

   * Печать первых и последних 5 элементов массивов `A`, `B` и `C`.
   * Замеры времени выполнения для всех размеров блока.
   * Сравнение производительности и визуальное выявление оптимального размера блока.

**Используемые технологии:**

* **C++ / CUDA** — реализация параллельного сложения массивов на GPU.
* **Global memory** — данные хранятся в глобальной памяти GPU.
* **cudaEvent_t** — точный замер времени работы GPU-ядра.
* **std::random / Mersenne Twister** — генерация случайных чисел.

**Применение:**

* Изучение влияния **конфигурации блоков и сетки на производительность CUDA-программы**.
* Демонстрация **увеличения или уменьшения времени выполнения** при изменении размера блока потоков.
* Формирование навыков **поиска оптимальных параметров ядра CUDA** для ускорения вычислений.


## Задание 3 (task3.cu)

**Описание:**
Данное задание посвящено изучению **коалесцированного и некоалесцированного доступа к глобальной памяти GPU**. Программа выполняет поэлементную обработку массива и демонстрирует, как шаблон доступа потоков к глобальной памяти влияет на производительность CUDA-программы.

**Цель задания:**

* Реализовать два варианта CUDA-ядра для обработки массива:

  1. **С коалесцированным доступом** — соседние потоки обращаются к соседним ячейкам памяти, что позволяет GPU эффективно объединять транзакции.
  2. **С некоалесцированным доступом** — потокам назначены «разрозненные» элементы памяти, что вызывает множество отдельных транзакций и снижает производительность.
* Сравнить **время выполнения** обеих версий для массива размером 1 000 000 элементов.
* Понять влияние **шаблона доступа к глобальной памяти** на скорость работы GPU-ядра.

**Функционал программы:**

1. **Инициализация данных:**

   * Генерация массива `data` длиной 1 000 000 элементов.
   * Выделение памяти на CPU (RAM) и GPU (VRAM).

2. **Запуск ядра с коалесцированным доступом:**

   * Каждый поток GPU обрабатывает элемент массива с линейной адресацией.
   * Использование глобальной памяти GPU с оптимизированным доступом.
   * Замер времени выполнения с помощью **cudaEvent_t**.

3. **Запуск ядра с некоалесцированным доступом:**

   * Нарочито «плохой» шаблон индексации потоков к элементам массива.
   * Эффект: множество отдельных обращений к глобальной памяти.
   * Замер времени выполнения.

4. **Сравнение производительности:**

   * Вывод первых и последних 5 элементов массива до и после обработки для проверки корректности.
   * Замеры времени выполнения обеих версий.
   * Расчет коэффициента замедления (`slowdown = uncoalesced / coalesced`).

**Используемые технологии:**

* **C++ / CUDA** — реализация параллельной обработки массива на GPU.
* **Global memory** — демонстрация разницы в производительности при коалесцированном и некоалесцированном доступе.
* **cudaEvent_t** — точный замер времени работы GPU-ядра.
* **std::random / Mersenne Twister** — генерация случайных чисел.

**Применение:**

* Изучение **эффекта шаблона доступа к глобальной памяти на производительность GPU**.
* Демонстрация **коалесцирования транзакций памяти** как важного аспекта оптимизации CUDA-программ.
* Формирование навыков анализа и оптимизации **структуры доступа потоков к памяти GPU**.

## Задание 4 (task4.cu)

**Описание:**
Данное задание посвящено **подбору оптимальной конфигурации сетки и блоков потоков CUDA**. Программа выполняет поэлементное сложение двух массивов и демонстрирует, как выбор размера блока влияет на производительность ядра. Задача позволяет определить оптимальный размер блока для конкретного массива и измерить ускорение относительно неоптимальной конфигурации.

**Цель задания:**

* Реализовать CUDA-программу для **поэлементного сложения двух массивов**.
* Исследовать влияние **размера блока потоков** на производительность ядра.
* Подобрать **оптимальную конфигурацию сетки и блоков** для заданного массива из 1 000 000 элементов.
* Сравнить производительность неоптимальной и оптимизированной конфигураций и рассчитать **speedup**.

**Функционал программы:**

1. **Инициализация данных:**

   * Генерация массивов `A` и `B` длиной 1 000 000 элементов.
   * Выделение памяти на CPU и GPU.

2. **Запуск ядра с разными размерами блока:**

   * Перебор нескольких размеров блока (32, 64, 128, 256, 512, 1024).
   * Замер времени выполнения каждого варианта с помощью событий **cudaEvent_t**.

3. **Определение оптимальной конфигурации:**

   * Сравнение времени выполнения для всех размеров блоков.
   * Выбор **размера блока с минимальным временем выполнения**.

4. **Сравнение и расчет эффективности:**

   * Вывод первых и последних 5 элементов массива результата для проверки корректности.
   * Расчет **коэффициента ускорения (speedup)** для каждого размера блока относительно оптимального.
   * Демонстрация того, как выбор блока влияет на производительность CUDA-ядра.

**Используемые технологии:**

* **C++ / CUDA** — поэлементное сложение массивов на GPU.
* **Global memory** — работа с глобальной памятью видеокарты.
* **cudaEvent_t** — точный замер времени выполнения ядра.
* **std::vector** — хранение и обработка результатов тестов.
* **std::random / Mersenne Twister** — генерация случайных чисел.

**Применение:**

* Оптимизация конфигурации CUDA-программы для максимальной производительности.
* Демонстрация **эффекта размера блока потоков на скорость работы GPU**.
* Формирование навыков анализа и выбора параметров сетки и блоков для эффективной работы CUDA-ядер.

**Используемые технологии**
- C++ / CUDA — написание GPU-ядр и хост-кода.
- Shared memory — ускорение вычислений внутри блоков.
- cudaEvent_t — точное измерение времени выполнения CUDA-ядр.
- std::random / Mersenne Twister — генерация случайных данных.
- std::vector / динамическая память — хранение массивов и результатов.

### Контрольные вопросы (`questions.md`)  

Файл содержит ответы на вопросы по GPU-памяти, структуре warp, конфигурации сетки и блоков, а также стратегии оптимизации CUDA-программ. 

**Файл решения:** questions.md
