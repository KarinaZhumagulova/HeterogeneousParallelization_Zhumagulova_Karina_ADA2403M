{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYFjdTt2CwWT",
        "outputId": "4ec9492c-0b2f-4ef8-a56b-16d53ba20a25"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 18 12:18:42 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NbAtpL4uRSh",
        "outputId": "74ccc402-9d8f-4b10-c5a8-23ceeb2a09db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 1"
      ],
      "metadata": {
        "id": "F90AzRUdA_fU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile assignment3_task1.cu\n",
        "#include <cuda_runtime.h> // Основной заголовочный файл CUDA для работы с рантаймом\n",
        "#include <iostream>       // Стандартный ввод-вывод C++\n",
        "#include <random>         // Библиотека для генерации случайных чисел\n",
        "#include <cstdlib>        // Стандартная библиотека (для malloc, exit)\n",
        "\n",
        "// Константы программы\n",
        "#define N 1000000         // Размер массива (1 миллион элементов)\n",
        "#define BLOCK_SIZE 256    // Количество потоков в одном блоке CUDA\n",
        "#define RAND_MIN_VAL 1    // Минимальное значение для рандома\n",
        "#define RAND_MAX_VAL 100000 // Максимальное значение для рандома\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// ===============================\n",
        "// Макрос для проверки ошибок CUDA\n",
        "// ===============================\n",
        "#define CUDA_CHECK(call) \\\n",
        "do { \\\n",
        "    cudaError_t err = call; \\\n",
        "    if (err != cudaSuccess) { \\\n",
        "        cerr << \"CUDA error: \" << cudaGetErrorString(err) \\\n",
        "             << \" at \" << __FILE__ << \":\" << __LINE__ << endl; \\\n",
        "        exit(EXIT_FAILURE); \\\n",
        "    } \\\n",
        "} while (0)\n",
        "\n",
        "// ===============================\n",
        "// Ядра (Kernels)\n",
        "// ===============================\n",
        "\n",
        "// Ядро, использующее только глобальную память GPU\n",
        "__global__ void multiply_global(float* data, float value, int n) {\n",
        "    // Вычисляем уникальный индекс потока во всей сетке\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Проверка границ: работаем только если индекс меньше размера массива\n",
        "    if (idx < n) {\n",
        "        data[idx] *= value; // Прямое чтение и запись в глобальную память\n",
        "    }\n",
        "}\n",
        "\n",
        "// Ядро, использующее разделяемую (shared) память\n",
        "__global__ void multiply_shared(float* data, float value, int n) {\n",
        "    // Объявляем массив в разделяемой памяти (быстрая память внутри блока)\n",
        "    __shared__ float buf[BLOCK_SIZE];\n",
        "\n",
        "    // Глобальный индекс элемента\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx < n) {\n",
        "        // 1. Копируем данные из медленной глобальной памяти в быструю разделяемую\n",
        "        buf[threadIdx.x] = data[idx];\n",
        "\n",
        "        // Синхронизация: ждем, пока все потоки блока заполнят буфер\n",
        "        __syncthreads();\n",
        "\n",
        "        // 2. Выполняем операцию в разделяемой памяти\n",
        "        buf[threadIdx.x] *= value;\n",
        "\n",
        "        // Синхронизация: ждем завершения вычислений перед записью обратно\n",
        "        __syncthreads();\n",
        "\n",
        "        // 3. Копируем результат обратно в глобальную память\n",
        "        data[idx] = buf[threadIdx.x];\n",
        "    }\n",
        "}\n",
        "\n",
        "// ===============================\n",
        "// Вспомогательная функция для печати краев массива\n",
        "// ===============================\n",
        "void print_edges(const float* a, const string& msg) {\n",
        "    cout << msg << \"\\nFirst 5: \";\n",
        "    for (int i = 0; i < 5; i++) cout << a[i] << \" \"; // Печать первых 5 элементов\n",
        "    cout << \"\\nLast 5:  \";\n",
        "    for (int i = N - 5; i < N; i++) cout << a[i] << \" \"; // Печать последних 5\n",
        "    cout << \"\\n\\n\";\n",
        "}\n",
        "\n",
        "// ===============================\n",
        "// Основная функция\n",
        "// ===============================\n",
        "int main() {\n",
        "    // Проверка наличия доступных GPU\n",
        "    int deviceCount = 0;\n",
        "    CUDA_CHECK(cudaGetDeviceCount(&deviceCount));\n",
        "    if (deviceCount == 0) {\n",
        "        cerr << \"ERROR: No CUDA GPU found. Enable GPU in Colab.\\n\";\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    float *h_data, *h_res, *d_data; // Указатели для хоста (CPU) и устройства (GPU)\n",
        "    float multiplier = 2.5f;        // Число, на которое будем умножать\n",
        "    size_t size = N * sizeof(float); // Общий размер выделяемой памяти в байтах\n",
        "\n",
        "    // Инициализация генератора случайных чисел\n",
        "    random_device rd;\n",
        "    mt19937 gen(rd());\n",
        "    uniform_int_distribution<> dist(RAND_MIN_VAL, RAND_MAX_VAL);\n",
        "\n",
        "    // Выделение памяти на хосте (RAM)\n",
        "    h_data = (float*)malloc(size);\n",
        "    h_res  = (float*)malloc(size);\n",
        "\n",
        "    // Заполнение исходного массива случайными числами\n",
        "    for (int i = 0; i < N; i++)\n",
        "        h_data[i] = static_cast<float>(dist(gen));\n",
        "\n",
        "    // Выделение памяти на устройстве (VRAM видеокарты)\n",
        "    CUDA_CHECK(cudaMalloc(&d_data, size));\n",
        "\n",
        "    // Расчет параметров сетки: сколько блоков нужно для N элементов\n",
        "    int grid = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "\n",
        "    // Создание событий CUDA для замера времени выполнения\n",
        "    cudaEvent_t start, stop;\n",
        "    CUDA_CHECK(cudaEventCreate(&start));\n",
        "    CUDA_CHECK(cudaEventCreate(&stop));\n",
        "\n",
        "    float time_global = 0.0f;\n",
        "    float time_shared = 0.0f;\n",
        "\n",
        "    // ===============================\n",
        "    // ТЕСТ 1: ГЛОБАЛЬНАЯ ПАМЯТЬ\n",
        "    // ===============================\n",
        "    cout << \"=== GLOBAL MEMORY VERSION ===\\n\";\n",
        "    print_edges(h_data, \"Before\");\n",
        "\n",
        "    // Копируем данные с CPU на GPU\n",
        "    CUDA_CHECK(cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice));\n",
        "\n",
        "    CUDA_CHECK(cudaEventRecord(start)); // Старт таймера\n",
        "    multiply_global<<<grid, BLOCK_SIZE>>>(d_data, multiplier, N); // Запуск ядра\n",
        "    CUDA_CHECK(cudaEventRecord(stop));  // Стоп таймера\n",
        "\n",
        "    CUDA_CHECK(cudaGetLastError());     // Проверка на ошибки при запуске ядра\n",
        "    CUDA_CHECK(cudaEventSynchronize(stop)); // Ждем завершения работы GPU\n",
        "    CUDA_CHECK(cudaEventElapsedTime(&time_global, start, stop)); // Считаем время\n",
        "\n",
        "    // Копируем результат обратно на CPU для проверки\n",
        "    CUDA_CHECK(cudaMemcpy(h_res, d_data, size, cudaMemcpyDeviceToHost));\n",
        "    print_edges(h_res, \"After\");\n",
        "\n",
        "    cout << \"Global memory kernel time: \" << time_global << \" ms\\n\\n\";\n",
        "\n",
        "    // ===============================\n",
        "    // ТЕСТ 2: РАЗДЕЛЯЕМАЯ ПАМЯТЬ\n",
        "    // ===============================\n",
        "    cout << \"=== SHARED MEMORY VERSION ===\\n\";\n",
        "    print_edges(h_data, \"Before\");\n",
        "\n",
        "    // Снова копируем исходные данные на GPU\n",
        "    CUDA_CHECK(cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice));\n",
        "\n",
        "    CUDA_CHECK(cudaEventRecord(start)); // Старт таймера\n",
        "    multiply_shared<<<grid, BLOCK_SIZE>>>(d_data, multiplier, N); // Запуск ядра\n",
        "    CUDA_CHECK(cudaEventRecord(stop));  // Стоп таймера\n",
        "\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "    CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "    CUDA_CHECK(cudaEventElapsedTime(&time_shared, start, stop));\n",
        "\n",
        "    CUDA_CHECK(cudaMemcpy(h_res, d_data, size, cudaMemcpyDeviceToHost));\n",
        "    print_edges(h_res, \"After\");\n",
        "\n",
        "    cout << \"Shared memory kernel time: \" << time_shared << \" ms\\n\\n\";\n",
        "\n",
        "    // ===============================\n",
        "    // ИТОГОВЫЙ ОТЧЕТ\n",
        "    // ===============================\n",
        "    cout << \"===== PERFORMANCE SUMMARY =====\\n\";\n",
        "    cout << \"Array size: \" << N << \" elements\\n\";\n",
        "    cout << \"Global memory time: \" << time_global << \" ms\\n\";\n",
        "    cout << \"Shared memory time: \" << time_shared << \" ms\\n\";\n",
        "    // Считаем коэффициент ускорения\n",
        "    cout << \"Speedup (global / shared): \" << time_global / time_shared << \"x\\n\";\n",
        "\n",
        "    // Освобождение ресурсов\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "    cudaFree(d_data); // Очистка памяти видеокарты\n",
        "    free(h_data);     // Очистка оперативной памяти\n",
        "    free(h_res);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06IYUaXznlS_",
        "outputId": "65bb101f-d900-4db6-bf93-8d329825101a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting assignment3_task1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 assignment3_task1.cu -o task1\n",
        "!./task1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW5ImVg-BGx0",
        "outputId": "7496ccda-6593-45ce-e670-65ff0e69d3bf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GLOBAL MEMORY VERSION ===\n",
            "Before\n",
            "First 5: 72614 13474 31816 70159 46710 \n",
            "Last 5:  41268 34592 29224 32633 51843 \n",
            "\n",
            "After\n",
            "First 5: 181535 33685 79540 175398 116775 \n",
            "Last 5:  103170 86480 73060 81582.5 129608 \n",
            "\n",
            "Global memory kernel time: 0.095296 ms\n",
            "\n",
            "=== SHARED MEMORY VERSION ===\n",
            "Before\n",
            "First 5: 72614 13474 31816 70159 46710 \n",
            "Last 5:  41268 34592 29224 32633 51843 \n",
            "\n",
            "After\n",
            "First 5: 181535 33685 79540 175398 116775 \n",
            "Last 5:  103170 86480 73060 81582.5 129608 \n",
            "\n",
            "Shared memory kernel time: 0.0456 ms\n",
            "\n",
            "===== PERFORMANCE SUMMARY =====\n",
            "Array size: 1000000 elements\n",
            "Global memory time: 0.095296 ms\n",
            "Shared memory time: 0.0456 ms\n",
            "Speedup (global / shared): 2.08982x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 2"
      ],
      "metadata": {
        "id": "7OsAA3uRETiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile assignment3_task2.cu\n",
        "#include <cuda_runtime.h> // Заголовочный файл для функций управления памятью и устройствами CUDA\n",
        "#include <iostream>       // Стандартный поток ввода-вывода C++\n",
        "#include <random>         // Современные средства C++ для генерации случайных чисел\n",
        "#include <cstdlib>        // Стандартные функции C (malloc, free, exit)\n",
        "\n",
        "#define N 1000000         // Длина векторов (1 миллион элементов)\n",
        "#define RAND_MIN_VAL 1    // Нижняя граница случайных чисел\n",
        "#define RAND_MAX_VAL 100  // Верхняя граница случайных чисел\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// ===============================\n",
        "// Макрос для проверки ошибок выполнения функций CUDA\n",
        "// ===============================\n",
        "#define CUDA_CHECK(call) \\\n",
        "do { \\\n",
        "    cudaError_t err = call; \\\n",
        "    if (err != cudaSuccess) { \\\n",
        "        cerr << \"CUDA error: \" << cudaGetErrorString(err) \\\n",
        "             << \" at \" << __FILE__ << \":\" << __LINE__ << endl; \\\n",
        "        exit(EXIT_FAILURE); \\\n",
        "    } \\\n",
        "} while (0)\n",
        "\n",
        "// ===============================\n",
        "// Ядро (Kernel): сложение векторов\n",
        "// ===============================\n",
        "// __global__ указывает, что функция вызывается с CPU и исполняется на GPU\n",
        "__global__ void vector_add(const float* a,\n",
        "                           const float* b,\n",
        "                           float* c,\n",
        "                           int n) {\n",
        "    // Вычисляем глобальный индекс потока: индекс блока * размер блока + индекс потока в блоке\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Проверка границ, чтобы потоки не вышли за пределы массива N\n",
        "    if (idx < n) {\n",
        "        c[idx] = a[idx] + b[idx]; // Каждый поток складывает один элемент\n",
        "    }\n",
        "}\n",
        "\n",
        "// ===============================\n",
        "// Вспомогательная функция для вывода первых и последних 5 элементов массива\n",
        "// ===============================\n",
        "void print_edges(const float* a, const string& msg) {\n",
        "    cout << msg << \"\\nFirst 5: \";\n",
        "    for (int i = 0; i < 5; i++) cout << a[i] << \" \"; // Начало массива\n",
        "    cout << \"\\nLast 5:  \";\n",
        "    for (int i = N - 5; i < N; i++) cout << a[i] << \" \"; // Конец массива\n",
        "    cout << \"\\n\\n\";\n",
        "}\n",
        "\n",
        "// ===============================\n",
        "// Функция запуска теста для конкретного размера блока\n",
        "// ===============================\n",
        "float run_test(int blockSize,\n",
        "               const float* h_a,\n",
        "               const float* h_b,\n",
        "               float* h_c,\n",
        "               float* d_a,\n",
        "               float* d_b,\n",
        "               float* d_c) {\n",
        "\n",
        "    // Рассчитываем количество блоков в сетке (Grid), чтобы покрыть N элементов\n",
        "    int gridSize = (N + blockSize - 1) / blockSize;\n",
        "\n",
        "    // Создаем события CUDA для точного измерения времени работы GPU\n",
        "    cudaEvent_t start, stop;\n",
        "    CUDA_CHECK(cudaEventCreate(&start));\n",
        "    CUDA_CHECK(cudaEventCreate(&stop));\n",
        "\n",
        "    // Записываем событие начала\n",
        "    CUDA_CHECK(cudaEventRecord(start));\n",
        "\n",
        "    // Запуск ядра с заданными параметрами сетки и блока\n",
        "    vector_add<<<gridSize, blockSize>>>(d_a, d_b, d_c, N);\n",
        "\n",
        "    // Записываем событие окончания\n",
        "    CUDA_CHECK(cudaEventRecord(stop));\n",
        "\n",
        "    // Проверяем наличие ошибок при запуске ядра\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "\n",
        "    // Ждем, пока GPU закончит выполнение всех задач до события stop\n",
        "    CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "\n",
        "    // Вычисляем разницу во времени между событиями\n",
        "    float time_ms = 0.0f;\n",
        "    CUDA_CHECK(cudaEventElapsedTime(&time_ms, start, stop));\n",
        "\n",
        "    // Копируем результат сложения с GPU обратно на CPU для возможной проверки\n",
        "    CUDA_CHECK(cudaMemcpy(h_c, d_c, N * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Удаляем события для освобождения ресурсов\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "    return time_ms; // Возвращаем время выполнения в миллисекундах\n",
        "}\n",
        "\n",
        "// ===============================\n",
        "// Главная функция программы\n",
        "// ===============================\n",
        "int main() {\n",
        "    // Проверяем наличие GPU с поддержкой CUDA\n",
        "    int deviceCount = 0;\n",
        "    CUDA_CHECK(cudaGetDeviceCount(&deviceCount));\n",
        "    if (deviceCount == 0) {\n",
        "        cerr << \"ERROR: No CUDA GPU found.\\n\";\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    size_t size = N * sizeof(float); // Объем памяти для массивов\n",
        "\n",
        "    // Указатели для памяти на хосте (CPU) и устройстве (GPU)\n",
        "    float *h_a, *h_b, *h_c;\n",
        "    float *d_a, *d_b, *d_c;\n",
        "\n",
        "    // Инициализация генератора случайных чисел\n",
        "    random_device rd;\n",
        "    mt19937 gen(rd());\n",
        "    uniform_int_distribution<> dist(RAND_MIN_VAL, RAND_MAX_VAL);\n",
        "\n",
        "    // Выделение оперативной памяти на CPU\n",
        "    h_a = (float*)malloc(size);\n",
        "    h_b = (float*)malloc(size);\n",
        "    h_c = (float*)malloc(size);\n",
        "\n",
        "    // Заполнение входных массивов случайными числами\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_a[i] = static_cast<float>(dist(gen));\n",
        "        h_b[i] = static_cast<float>(dist(gen));\n",
        "    }\n",
        "\n",
        "    // Выделение видеопамяти на GPU\n",
        "    CUDA_CHECK(cudaMalloc(&d_a, size));\n",
        "    CUDA_CHECK(cudaMalloc(&d_b, size));\n",
        "    CUDA_CHECK(cudaMalloc(&d_c, size));\n",
        "\n",
        "    // Копирование исходных данных из RAM (CPU) в VRAM (GPU)\n",
        "    CUDA_CHECK(cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // Вывод исходных значений (краев)\n",
        "    print_edges(h_a, \"Array A\");\n",
        "    print_edges(h_b, \"Array B\");\n",
        "\n",
        "    // Список размеров блоков, которые мы хотим протестировать\n",
        "    int blockSizes[] = {32, 64, 128, 256, 512};\n",
        "\n",
        "    cout << \"===== PERFORMANCE RESULTS =====\\n\";\n",
        "    cout << \"Array size: \" << N << \" elements\\n\\n\";\n",
        "\n",
        "    // Цикл по разным размерам блока для сравнения производительности\n",
        "    for (int bs : blockSizes) {\n",
        "        float time = run_test(bs, h_a, h_b, h_c, d_a, d_b, d_c);\n",
        "        cout << \"Block size \" << bs\n",
        "             << \": \" << time << \" ms\\n\";\n",
        "    }\n",
        "\n",
        "    // Вывод итогового массива C (краев) для подтверждения корректности\n",
        "    print_edges(h_c, \"\\nResult array C = A + B\");\n",
        "\n",
        "    // Освобождение памяти на видеокарте\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    // Освобождение памяти в системе\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkbK8KxzD-k5",
        "outputId": "bae7fe2d-4728-437d-a2a0-c7c6038c6206"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting assignment3_task2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 assignment3_task2.cu -o task2\n",
        "!./task2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmjZLTfHFH4m",
        "outputId": "2a8a527e-554e-4a09-f396-de437580fd58"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array A\n",
            "First 5: 15 85 37 49 96 \n",
            "Last 5:  35 32 22 48 67 \n",
            "\n",
            "Array B\n",
            "First 5: 90 2 70 68 43 \n",
            "Last 5:  86 65 69 14 59 \n",
            "\n",
            "===== PERFORMANCE RESULTS =====\n",
            "Array size: 1000000 elements\n",
            "\n",
            "Block size 32: 0.204896 ms\n",
            "Block size 64: 0.06016 ms\n",
            "Block size 128: 0.05392 ms\n",
            "Block size 256: 0.055456 ms\n",
            "Block size 512: 0.079904 ms\n",
            "\n",
            "Result array C = A + B\n",
            "First 5: 105 87 107 117 139 \n",
            "Last 5:  121 97 91 62 126 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 3"
      ],
      "metadata": {
        "id": "QeO8iB7FGanv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile assignment3_task3.cu\n",
        "#include <cuda_runtime.h> // Библиотека среды выполнения CUDA\n",
        "#include <iostream>       // Стандартный ввод-вывод\n",
        "#include <random>         // Генерация случайных чисел\n",
        "\n",
        "// Константы\n",
        "#define N 1000000         // Количество элементов в массиве\n",
        "#define BLOCK_SIZE 256    // Количество потоков в одном блоке\n",
        "#define RAND_MIN_VAL 1    // Минимальное случайное значение\n",
        "#define RAND_MAX_VAL 100  // Максимальное случайное значение\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// -----------------------------\n",
        "// Макрос для автоматической проверки ошибок CUDA-функций\n",
        "// -----------------------------\n",
        "#define CUDA_CHECK(call) \\\n",
        "do { \\\n",
        "    cudaError_t err = call; \\\n",
        "    if (err != cudaSuccess) { \\\n",
        "        cerr << \"CUDA error: \" << cudaGetErrorString(err) \\\n",
        "             << \" at \" << __FILE__ << \":\" << __LINE__ << endl; \\\n",
        "        exit(EXIT_FAILURE); \\\n",
        "    } \\\n",
        "} while(0)\n",
        "\n",
        "// -----------------------------\n",
        "// Ядра (Kernels)\n",
        "// -----------------------------\n",
        "\n",
        "// 1. Ядро с коалесцированным доступом (Эффективно)\n",
        "// Потоки одного варпа (группа из 32 потоков) обращаются к соседним ячейкам памяти.\n",
        "// Контроллер памяти может объединить эти запросы в одну транзакцию.\n",
        "__global__ void coalesced_kernel(float* data, float factor, int n) {\n",
        "    // Стандартное вычисление индекса: поток 0 -> элемент 0, поток 1 -> элемент 1\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if(idx < n) data[idx] *= factor;\n",
        "}\n",
        "\n",
        "// 2. Ядро с некоалесцированным доступом (Неэффективно)\n",
        "// Здесь индекс вычисляется так, что соседние потоки читают данные из очень далеких участков памяти.\n",
        "// Это заставляет видеокарту выполнять множество отдельных транзакций вместо одной.\n",
        "__global__ void uncoalesced_kernel(float* data, float factor, int n) {\n",
        "    // Нарочито \"плохая\" формула индексации\n",
        "    int idx = threadIdx.x * gridDim.x + blockIdx.x;\n",
        "    if(idx < n) data[idx] *= factor;\n",
        "}\n",
        "\n",
        "// -----------------------------\n",
        "// Вспомогательная функция для печати данных\n",
        "// -----------------------------\n",
        "void print_edges(const float* a, const string& msg) {\n",
        "    cout << msg << \"\\nFirst 5: \";\n",
        "    for(int i=0;i<5;i++) cout<<a[i]<<\" \"; // Печать начала\n",
        "    cout<<\"\\nLast 5: \";\n",
        "    for(int i=N-5;i<N;i++) cout<<a[i]<<\" \"; // Печать конца\n",
        "    cout<<\"\\n\\n\";\n",
        "}\n",
        "\n",
        "// -----------------------------\n",
        "// Основная функция\n",
        "// -----------------------------\n",
        "int main() {\n",
        "    // Проверка наличия видеокарты\n",
        "    int deviceCount = 0;\n",
        "    CUDA_CHECK(cudaGetDeviceCount(&deviceCount));\n",
        "    if(deviceCount==0) { cerr<<\"No CUDA GPU found\\n\"; return 1; }\n",
        "\n",
        "    float *h_data, *h_res, *d_data; // Указатели для CPU (h_) и GPU (d_)\n",
        "    size_t size = N*sizeof(float);  // Общий объем памяти в байтах\n",
        "    float factor = 2.5f;            // Множитель\n",
        "\n",
        "    // Инициализация случайных чисел на хосте\n",
        "    random_device rd;\n",
        "    mt19937 gen(rd());\n",
        "    uniform_int_distribution<> dist(RAND_MIN_VAL, RAND_MAX_VAL);\n",
        "\n",
        "    h_data = (float*)malloc(size); // Выделение RAM\n",
        "    h_res  = (float*)malloc(size); // Память для хранения результата после копирования\n",
        "    for(int i=0;i<N;i++) h_data[i] = static_cast<float>(dist(gen));\n",
        "\n",
        "    // Выделение видеопамяти\n",
        "    CUDA_CHECK(cudaMalloc(&d_data, size));\n",
        "\n",
        "    // Расчет количества блоков\n",
        "    int grid = (N + BLOCK_SIZE -1)/BLOCK_SIZE;\n",
        "\n",
        "    // Создание событий для замера времени\n",
        "    cudaEvent_t start, stop;\n",
        "    CUDA_CHECK(cudaEventCreate(&start));\n",
        "    CUDA_CHECK(cudaEventCreate(&stop));\n",
        "    float time_coalesced = 0.0f;\n",
        "    float time_uncoalesced = 0.0f;\n",
        "\n",
        "    // ========================\n",
        "    // ТЕСТ 1: КОАЛЕСЦИРОВАННЫЙ ДОСТУП\n",
        "    // ========================\n",
        "    cout<<\"=== COALESCED ACCESS ===\\n\";\n",
        "    print_edges(h_data,\"Before\");\n",
        "\n",
        "    // Копирование данных на GPU\n",
        "    CUDA_CHECK(cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice));\n",
        "\n",
        "    CUDA_CHECK(cudaEventRecord(start)); // Запуск секундомера\n",
        "    coalesced_kernel<<<grid,BLOCK_SIZE>>>(d_data,factor,N); // Вызов ядра\n",
        "    CUDA_CHECK(cudaEventRecord(stop));  // Остановка секундомера\n",
        "\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "    CUDA_CHECK(cudaEventSynchronize(stop)); // Синхронизация CPU и GPU\n",
        "    CUDA_CHECK(cudaEventElapsedTime(&time_coalesced,start,stop)); // Расчет времени в мс\n",
        "\n",
        "    // Копирование результата обратно для проверки\n",
        "    CUDA_CHECK(cudaMemcpy(h_res,d_data,size,cudaMemcpyDeviceToHost));\n",
        "    print_edges(h_res,\"After\");\n",
        "    cout<<\"Time: \"<<time_coalesced<<\" ms\\n\\n\";\n",
        "\n",
        "    // ========================\n",
        "    // ТЕСТ 2: НЕКОАЛЕСЦИРОВАННЫЙ ДОСТУП\n",
        "    // ========================\n",
        "    cout<<\"=== UNCOALESCED ACCESS ===\\n\";\n",
        "    print_edges(h_data,\"Before\");\n",
        "\n",
        "    // Сброс данных на GPU в исходное состояние\n",
        "    CUDA_CHECK(cudaMemcpy(d_data,h_data,size,cudaMemcpyHostToDevice));\n",
        "\n",
        "    CUDA_CHECK(cudaEventRecord(start));\n",
        "    uncoalesced_kernel<<<grid,BLOCK_SIZE>>>(d_data,factor,N); // Вызов \"плохого\" ядра\n",
        "    CUDA_CHECK(cudaEventRecord(stop));\n",
        "\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "    CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "    CUDA_CHECK(cudaEventElapsedTime(&time_uncoalesced,start,stop));\n",
        "\n",
        "    CUDA_CHECK(cudaMemcpy(h_res,d_data,size,cudaMemcpyDeviceToHost));\n",
        "    print_edges(h_res,\"After\");\n",
        "    cout<<\"Time: \"<<time_uncoalesced<<\" ms\\n\\n\";\n",
        "\n",
        "    // ========================\n",
        "    // РАСЧЕТ ЗАМЕДЛЕНИЯ\n",
        "    // ========================\n",
        "    float slowdown = time_uncoalesced / time_coalesced;\n",
        "    cout<<\"===== PERFORMANCE COMPARISON =====\\n\";\n",
        "    cout<<\"Coalesced access time:   \"<<time_coalesced<<\" ms\\n\";\n",
        "    cout<<\"Uncoalesced access time: \"<<time_uncoalesced<<\" ms\\n\";\n",
        "    cout<<\"Slowdown (uncoalesced / coalesced): \"<<slowdown<<\"x\\n\\n\";\n",
        "\n",
        "    // Очистка памяти и уничтожение событий\n",
        "    CUDA_CHECK(cudaEventDestroy(start));\n",
        "    CUDA_CHECK(cudaEventDestroy(stop));\n",
        "    cudaFree(d_data);\n",
        "    free(h_data);\n",
        "    free(h_res);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NZwf9bnID6Q",
        "outputId": "dcbeee3b-bb3f-46e7-dd55-55c19e724dff"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting assignment3_task3.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 assignment3_task3.cu -o task3\n",
        "!./task3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CgeVl9wFRuf",
        "outputId": "f6e2ef4b-f9ff-43d5-9137-f90283649695"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== COALESCED ACCESS ===\n",
            "Before\n",
            "First 5: 53 99 89 55 51 \n",
            "Last 5: 40 50 15 8 32 \n",
            "\n",
            "After\n",
            "First 5: 132.5 247.5 222.5 137.5 127.5 \n",
            "Last 5: 100 125 37.5 20 80 \n",
            "\n",
            "Time: 0.118816 ms\n",
            "\n",
            "=== UNCOALESCED ACCESS ===\n",
            "Before\n",
            "First 5: 53 99 89 55 51 \n",
            "Last 5: 40 50 15 8 32 \n",
            "\n",
            "After\n",
            "First 5: 132.5 247.5 222.5 137.5 127.5 \n",
            "Last 5: 100 125 37.5 20 80 \n",
            "\n",
            "Time: 0.268736 ms\n",
            "\n",
            "===== PERFORMANCE COMPARISON =====\n",
            "Coalesced access time:   0.118816 ms\n",
            "Uncoalesced access time: 0.268736 ms\n",
            "Slowdown (uncoalesced / coalesced): 2.26178x\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 4"
      ],
      "metadata": {
        "id": "4cGhnh5YJtHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile assignment3_task4.cu\n",
        "#include <cuda_runtime.h> // Библиотека среды выполнения CUDA для работы с GPU\n",
        "#include <iostream>       // Стандартная библиотека ввода-вывода\n",
        "#include <random>         // Библиотека для генерации случайных чисел\n",
        "#include <vector>         // Контейнер вектор для хранения результатов\n",
        "#include <iomanip>        // Библиотека для форматирования вывода (например, точность чисел)\n",
        "\n",
        "#define N 1000000         // Общее количество элементов в массивах\n",
        "#define RAND_MIN_VAL 1    // Минимальное значение случайного числа\n",
        "#define RAND_MAX_VAL 10000 // Максимальное значение случайного числа\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// -----------------------------\n",
        "// Макрос для проверки ошибок выполнения CUDA\n",
        "// -----------------------------\n",
        "#define CUDA_CHECK(call) \\\n",
        "do { \\\n",
        "    cudaError_t err = call; \\\n",
        "    if (err != cudaSuccess) { \\\n",
        "        cerr << \"CUDA error: \" << cudaGetErrorString(err) \\\n",
        "             << \" at \" << __FILE__ << \":\" << __LINE__ << endl; \\\n",
        "        exit(EXIT_FAILURE); \\\n",
        "    } \\\n",
        "} while(0)\n",
        "\n",
        "// -----------------------------\n",
        "// Ядро (Kernel): параллельное сложение векторов\n",
        "// -----------------------------\n",
        "__global__ void vector_add(const float* a, const float* b, float* c, int n) {\n",
        "    // Рассчитываем уникальный глобальный индекс потока\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    // Проверка, чтобы индекс не вышел за пределы массива\n",
        "    if(idx < n) c[idx] = a[idx] + b[idx];\n",
        "}\n",
        "\n",
        "// -----------------------------\n",
        "// Вспомогательная функция для вывода краев массива (начала и конца)\n",
        "// -----------------------------\n",
        "void print_edges(const float* a, const string& msg) {\n",
        "    cout << msg << \"\\nFirst 5: \";\n",
        "    for(int i=0;i<5;i++) cout<<a[i]<<\" \"; // Печать первых 5 элементов\n",
        "    cout<<\"\\nLast 5: \";\n",
        "    for(int i=N-5;i<N;i++) cout<<a[i]<<\" \"; // Печать последних 5 элементов\n",
        "    cout<<\"\\n\\n\";\n",
        "}\n",
        "\n",
        "// -----------------------------\n",
        "// Функция запуска теста для конкретного размера блока\n",
        "// -----------------------------\n",
        "float run_test(int blockSize, const float* h_a, const float* h_b, float* h_c,\n",
        "               float* d_a, float* d_b, float* d_c) {\n",
        "    // Вычисляем размер сетки (Grid) в зависимости от размера блока\n",
        "    int gridSize = (N + blockSize - 1)/blockSize;\n",
        "\n",
        "    // Переменные для событий (таймеров)\n",
        "    cudaEvent_t start, stop;\n",
        "    CUDA_CHECK(cudaEventCreate(&start));\n",
        "    CUDA_CHECK(cudaEventCreate(&stop));\n",
        "\n",
        "    // Записываем начало события\n",
        "    CUDA_CHECK(cudaEventRecord(start));\n",
        "    // Запуск ядра на GPU\n",
        "    vector_add<<<gridSize, blockSize>>>(d_a, d_b, d_c, N);\n",
        "    // Записываем окончание события\n",
        "    CUDA_CHECK(cudaEventRecord(stop));\n",
        "\n",
        "    // Проверка на наличие ошибок запуска\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "    // Ожидание завершения работы GPU\n",
        "    CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "\n",
        "    float time_ms;\n",
        "    // Получаем время в миллисекундах между событиями\n",
        "    CUDA_CHECK(cudaEventElapsedTime(&time_ms, start, stop));\n",
        "\n",
        "    // Копируем полученный результат из GPU в CPU (хост)\n",
        "    CUDA_CHECK(cudaMemcpy(h_c, d_c, N*sizeof(float), cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Освобождаем ресурсы событий\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "    return time_ms; // Возвращаем время выполнения\n",
        "}\n",
        "\n",
        "// -----------------------------\n",
        "// Основная логика программы\n",
        "// -----------------------------\n",
        "int main() {\n",
        "    // Проверка наличия устройств CUDA\n",
        "    int deviceCount = 0;\n",
        "    CUDA_CHECK(cudaGetDeviceCount(&deviceCount));\n",
        "    if(deviceCount==0) { cerr<<\"No CUDA GPU found\\n\"; return 1; }\n",
        "\n",
        "    size_t size = N * sizeof(float); // Размер памяти для массива в байтах\n",
        "    float *h_a, *h_b, *h_c;          // Указатели для оперативной памяти (Host)\n",
        "    float *d_a, *d_b, *d_c;          // Указатели для видеопамяти (Device)\n",
        "\n",
        "    // Инициализация генератора случайных чисел\n",
        "    random_device rd; mt19937 gen(rd()); uniform_int_distribution<> dist(RAND_MIN_VAL, RAND_MAX_VAL);\n",
        "\n",
        "    // Выделение памяти на CPU\n",
        "    h_a = (float*)malloc(size);\n",
        "    h_b = (float*)malloc(size);\n",
        "    h_c = (float*)malloc(size);\n",
        "\n",
        "    // Заполнение входных массивов случайными числами\n",
        "    for(int i=0;i<N;i++) { h_a[i] = dist(gen); h_b[i] = dist(gen); }\n",
        "\n",
        "    // Выделение памяти на GPU\n",
        "    CUDA_CHECK(cudaMalloc(&d_a,size));\n",
        "    CUDA_CHECK(cudaMalloc(&d_b,size));\n",
        "    CUDA_CHECK(cudaMalloc(&d_c,size));\n",
        "\n",
        "    // Копирование входных векторов из CPU в GPU\n",
        "    CUDA_CHECK(cudaMemcpy(d_a,h_a,size,cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_b,h_b,size,cudaMemcpyHostToDevice));\n",
        "\n",
        "    // Вывод исходных данных\n",
        "    print_edges(h_a,\"Array A\");\n",
        "    print_edges(h_b,\"Array B\");\n",
        "\n",
        "    // ===============================\n",
        "    // Тестирование различных размеров блоков\n",
        "    // ===============================\n",
        "    vector<int> blockSizes = {32, 64, 128, 256, 512, 1024}; // Список размеров для проверки\n",
        "    vector<float> times(blockSizes.size());                 // Массив для хранения времени\n",
        "    float minTime = 1e9;                                    // Начальное значение для поиска минимума\n",
        "    int optimalBlock = 0;                                   // Переменная для хранения лучшего размера блока\n",
        "\n",
        "    cout<<\"===== PERFORMANCE RESULTS =====\\n\";\n",
        "    for(size_t i=0;i<blockSizes.size();i++) {\n",
        "        // Выполняем тест и сохраняем время\n",
        "        times[i] = run_test(blockSizes[i],h_a,h_b,h_c,d_a,d_b,d_c);\n",
        "        cout<<\"Block size \"<<blockSizes[i]<<\": \"<<times[i]<<\" ms\\n\";\n",
        "\n",
        "        // Поиск минимального времени\n",
        "        if(times[i] < minTime) {\n",
        "            minTime = times[i];\n",
        "            optimalBlock = blockSizes[i];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Вывод контрольного результата вычислений\n",
        "    print_edges(h_c,\"\\nResult array C = A + B\");\n",
        "\n",
        "    // ===============================\n",
        "    // Расчет эффективности\n",
        "    // ===============================\n",
        "    cout<<\"\\n===== OPTIMAL CONFIGURATION =====\\n\";\n",
        "    cout<<\"Optimal block size: \"<<optimalBlock<<\"\\n\";\n",
        "    cout<<\"Minimum execution time: \"<<minTime<<\" ms\\n\";\n",
        "\n",
        "    cout<<\"\\n===== SPEEDUP RELATIVE TO OPTIMAL BLOCK =====\\n\";\n",
        "    cout << fixed << setprecision(2); // Установка точности до 2 знаков после запятой\n",
        "    for(size_t i=0;i<blockSizes.size();i++) {\n",
        "        // Расчет замедления/ускорения (насколько текущее время больше оптимального)\n",
        "        float speedup = times[i]/minTime;\n",
        "        cout<<\"Block size \"<<blockSizes[i]<<\": \"<<speedup<<\"x\\n\";\n",
        "    }\n",
        "\n",
        "    // Очистка памяти\n",
        "    CUDA_CHECK(cudaFree(d_a));\n",
        "    CUDA_CHECK(cudaFree(d_b));\n",
        "    CUDA_CHECK(cudaFree(d_c));\n",
        "    free(h_a); free(h_b); free(h_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De9FZ6wvIQKy",
        "outputId": "5c017960-c49e-4c4c-b603-ade4684ccbec"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting assignment3_task4.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 assignment3_task4.cu -o task4\n",
        "!./task4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct2AyfB3KL6Q",
        "outputId": "023703d4-74cb-4f44-b2d4-caa97c185d25"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array A\n",
            "First 5: 3520 592 3529 4729 847 \n",
            "Last 5: 3806 2235 4886 2687 7336 \n",
            "\n",
            "Array B\n",
            "First 5: 198 4717 8532 4195 3120 \n",
            "Last 5: 7552 3605 1597 5273 9851 \n",
            "\n",
            "===== PERFORMANCE RESULTS =====\n",
            "Block size 32: 0.2352 ms\n",
            "Block size 64: 0.061632 ms\n",
            "Block size 128: 0.05552 ms\n",
            "Block size 256: 0.054368 ms\n",
            "Block size 512: 0.055328 ms\n",
            "Block size 1024: 0.06016 ms\n",
            "\n",
            "Result array C = A + B\n",
            "First 5: 3718 5309 12061 8924 3967 \n",
            "Last 5: 11358 5840 6483 7960 17187 \n",
            "\n",
            "\n",
            "===== OPTIMAL CONFIGURATION =====\n",
            "Optimal block size: 256\n",
            "Minimum execution time: 0.054368 ms\n",
            "\n",
            "===== SPEEDUP RELATIVE TO OPTIMAL BLOCK =====\n",
            "Block size 32: 4.33x\n",
            "Block size 64: 1.13x\n",
            "Block size 128: 1.02x\n",
            "Block size 256: 1.00x\n",
            "Block size 512: 1.02x\n",
            "Block size 1024: 1.11x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ngVnEGGMKONx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}