# Контрольные вопросы к Assignment 3
## 1. Какие основные типы памяти существуют в архитектуре CUDA и чем они отличаются по скорости доступа?

В архитектуре CUDA выделяют несколько уровней памяти, образующих иерархию:

* **Регистры (Registers):** Самая быстрая память. Находятся непосредственно в вычислительном ядре. Доступ практически мгновенный. Используются для хранения локальных переменных потока.
* **Разделяемая память (Shared Memory):** Очень быстрая память (в десятки раз быстрее глобальной), расположенная внутри мультипроцессора (SM). Она общая для всех потоков одного блока.
* **Константная и текстурная память (Constant/Texture Memory):** Специализированные виды памяти, имеющие кэширование. Быстрее глобальной при определенных сценариях чтения.
* **Глобальная память (Global Memory):** Самая большая (видеопамять GPU), но и самая медленная (задержки доступа в сотни тактов). К ней имеют доступ все потоки и хост (CPU).

## 2. В каких случаях использование разделяемой памяти позволяет ускорить выполнение CUDA-программы?

Использование разделяемой памяти эффективно, когда:

* **Повторное использование данных:** Одни и те же данные из глобальной памяти нужны потокам блока многократно (например, при умножении матриц или свертке). Мы один раз загружаем их в `Shared`, а затем быстро читаем оттуда.
* **Сложный шаблон доступа:** Если потокам нужно читать данные «вразнобой» (некоалесцированно), можно сначала загрузить их в разделяемую память коалесцированным способом, а затем внутри блока обращаться к ним как угодно без потерь скорости.
* **Взаимодействие потоков:** Когда потокам внутри блока нужно обмениваться результатами вычислений.

## 3. Как шаблон доступа к глобальной памяти влияет на производительность GPU-программы?

GPU эффективнее всего работает с памятью, когда используется **коалесцированный доступ (coalesced access)**. Это происходит, когда последовательные потоки в варпе обращаются к последовательным адресам в глобальной памяти.

* **Хорошо:** Поток 0 читает адрес `X`, поток 1 — адрес `X+1` и т.д. В этом случае контроллер памяти объединяет все запросы в одну транзакцию.
* **Плохо:** Если потоки читают данные с большим шагом (stride) или хаотично, контроллеру приходится выполнять множество отдельных транзакций, что резко снижает пропускную способность.

## 4. Почему одинаковый алгоритм на GPU может показывать разное время выполнения при разных способах обращения к памяти?

Потому что в GPU **память является главным узким местом (bottleneck)**.
Вычислительная мощность GPU огромна, но она часто простаивает, ожидая данные из медленной глобальной памяти. Если один способ обращения позволяет объединить запросы (коалесценция) или использовать быстрый кэш (разделяемая память), а другой — заставляет GPU делать сотни лишних запросов к видеопамяти, время выполнения будет отличаться в разы, даже если математические операции абсолютно идентичны.

## 5. Как размер блока потоков влияет на производительность CUDA-ядра?

Размер блока определяет «заполняемость» (occupancy) мультипроцессора.

* **Слишком маленький блок (например, 32):** Не позволяет GPU эффективно скрывать задержки доступа к памяти.
* **Слишком большой блок (например, 1024):** Может ограничить количество активных блоков на одном SM, так как ресурсы (регистры и Shared Memory) делятся между всеми потоками.
* **Оптимальный размер:** Обычно кратен 32 (размеру варпа) и чаще всего находится в диапазоне от 128 до 512 потоков.

## 6. Что такое варп и почему важно учитывать его при разработке CUDA-программ?

**Варп (Warp)** — это базовая единица исполнения на GPU, состоящая из **32 потоков**. Все потоки в варпе выполняют одну и ту же инструкцию одновременно (принцип SIMT — Single Instruction, Multiple Threads).
**Почему это важно:**

* Если в варпе возникает ветвление (`if/else`), и разные потоки идут по разным путям, возникает **warp divergence** — потоки выполняют пути по очереди, что вдвое снижает скорость.
* Все оптимизации памяти (коалесценция) проектируются именно под уровень варпа.

## 7. Какие факторы необходимо учитывать при выборе конфигурации сетки и блоков потоков?

При выборе `<<<grid, block>>>` нужно учитывать:

1. **Общее количество элементов (N):** Количество потоков должно быть не меньше N (обычно `(N + blockSize - 1) / blockSize`).
2. **Аппаратные ограничения:** Максимальное число потоков в блоке (обычно 1024) и количество регистров на поток.
3. **Кратность 32:** Размер блока всегда должен быть кратен 32 для эффективной работы варпов.
4. **Баланс ресурсов:** Выбор такого размера блока, который обеспечит максимальную загрузку (occupancy) всех SM на конкретной видеокарте.

## 8. Почему оптимизация CUDA-программы часто начинается с анализа работы с памятью, а не с изменения алгоритма?

Это связано с тем, что большинство задач на GPU ограничены **пропускной способностью памяти (Memory-Bound)**, а не скоростью вычислений (Compute-Bound).
Даже самый оптимальный математический алгоритм будет работать медленно, если данные в ядра поступают по «узкому каналу» из глобальной памяти. Устранение некоалесцированного доступа или внедрение разделяемой памяти часто дает ускорение в 10–50 раз, в то время как оптимизация самих формул может дать лишь 10–20% прироста.
