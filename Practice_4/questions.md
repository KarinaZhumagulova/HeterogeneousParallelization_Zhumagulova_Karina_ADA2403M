# Контрольные вопросы к Практической работе №4 Оптимизация параллельного кода на GPU с использованием различных типов памяти

## 1. Чем отличаются типы памяти в CUDA и в каких случаях их использовать?
В архитектуре CUDA память организована иерархически и различается по скорости, объему и области видимости:
* Регистры (Registers): Самая быстрая память с очень низкой задержкой. Используются для хранения локальных, часто используемых переменных каждого отдельного потока.
* Разделяемая память (Shared Memory): Обладает низкой задержкой и предназначена для взаимодействия потоков внутри одного блока. Используется как быстрый «блокнот» для обмена данными и временного хранения.
* Глобальная память (Global Memory): Имеет самый большой объем (ГБ), но очень высокую задержку доступа (сотни тактов). Это основная область для хранения входных и выходных данных, доступная всем потокам.
* Константная память (Constant Memory): Ограничена объемом (64 КБ) и оптимизирована для чтения неизменяемых данных всеми потоками одновременно.
* Локальная память (Local Memory): Фактически находится в глобальной памяти и имеет высокую задержку. Туда попадают переменные, которые не поместились в регистры.
* Текстурная и поверхностная память: Оптимизированы для 2D-данных и произвольного доступа с использованием кэширования.
## 2. Как использование разделяемой памяти влияет на производительность?
## 3. Доступ и как его обеспечить?
## 4. Какие сложности возникают при работе с большим объемом данных на GPU?
## 5. Почему важно минимизировать доступ к глобальной памяти?
## 6. Как использовать профилирование для анализа производительности CUDA-программ?
