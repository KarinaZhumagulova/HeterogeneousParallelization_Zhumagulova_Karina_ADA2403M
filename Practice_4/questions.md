# Контрольные вопросы к Практической работе №4 Оптимизация параллельного кода на GPU с использованием различных типов памяти

## 1. Чем отличаются типы памяти в CUDA и в каких случаях их использовать?

В архитектуре CUDA память организована иерархически и различается по скорости доступа, объёму и области видимости.
* Регистры (Registers) — самая быстрая память с минимальной задержкой, индивидуальная для каждого потока. Используется для хранения часто используемых локальных переменных.
* Разделяемая память (Shared Memory) — быстрая память, общая для потоков одного блока. Применяется для обмена данными между потоками и временного хранения данных, активно используемых внутри блока.
* Глобальная память (Global Memory) — обладает наибольшим объёмом, но высокой задержкой доступа. Используется для хранения входных и выходных данных, доступных всем потокам.
* Константная память (Constant Memory) — ограничена по объёму (64 КБ) и оптимизирована для чтения неизменяемых данных всеми потоками.
* Локальная память (Local Memory) — логически принадлежит одному потоку, но физически размещается в глобальной памяти. Используется при нехватке регистров и характеризуется высокой задержкой.
* Текстурная и поверхностная память — предназначены для 2D-данных и нерегулярного доступа с использованием кэширования.
  
## 2. Как использование разделяемой памяти влияет на производительность?

Использование разделяемой памяти существенно повышает производительность GPU-программ, так как:
* обеспечивает низкую задержку доступа по сравнению с глобальной памятью;
* позволяет сократить количество обращений к глобальной памяти, загружая данные один раз и повторно используя их внутри блока;
* упрощает координацию и синхронизацию потоков, например, в алгоритмах редукции и матричного умножения.

При этом необходимо учитывать возможные банковские конфликты, которые могут снизить эффективность при неправильной организации данных.

## 3. Доступ и как его обеспечить?

Согласованный доступ (coalesced memory access) — это режим доступа к глобальной памяти, при котором обращения потоков одного варпа объединяются в минимальное количество транзакций, что повышает пропускную способность памяти.

Для обеспечения согласованного доступа необходимо:
* чтобы потоки варпа обращались к последовательным адресам памяти;
* использовать линейную индексацию массивов;
* обеспечивать корректное выравнивание данных в памяти.

## 4. Какие сложности возникают при работе с большим объемом данных на GPU?

При обработке больших массивов данных на GPU могут возникать следующие сложности:
* ограниченный объём видеопамяти устройства;
* высокие накладные расходы при передаче данных между CPU и GPU;
* снижение производительности из-за несогласованного доступа к глобальной памяти;
* банковские конфликты при работе с разделяемой памятью;
* пролив регистров (register spilling), при котором данные перемещаются в медленную локальную память.
  
## 5. Почему важно минимизировать доступ к глобальной памяти?

Минимизация обращений к глобальной памяти критична, поскольку:
* она обладает высокой задержкой доступа;
* неконтролируемые обращения могут быстро исчерпать пропускную способность памяти;
* операции доступа к глобальной памяти являются энергоёмкими.

Для оптимизации используются регистры и разделяемая память, что позволяет существенно ускорить выполнение программы.

## 6. Как использовать профилирование для анализа производительности CUDA-программ?

Профилирование используется для выявления узких мест и оценки эффективности оптимизаций. Оно позволяет:
* анализировать характер доступа к памяти и выявлять несогласованные обращения;
* обнаруживать банковские конфликты в разделяемой памяти;
* отслеживать дивергенцию варпов;
* оценивать уровень загрузки мультипроцессоров (SM).

Для этого применяются инструменты NVIDIA Nsight Compute и NVIDIA Nsight Systems, которые помогают количественно оценить производительность и корректность оптимизаций.
