# Контрольные вопросы к Практической работе №5 Тема: Реализация параллельных структур данных на GPU

## 1. В чём отличие стека и очереди?
Стек и очередь отличаются **логикой доступа к элементам**, то есть порядком добавления и извлечения данных:
**Стек (LIFO — Last In, First Out)** — это структура данных, в которой:
* добавление (`push`) и удаление (`pop`) элементов происходит **с одного конца**;
* последний добавленный элемент извлекается первым.
Данная структура широко используется при реализации:
* рекурсии,
* обработки вызовов функций,
* алгоритмов поиска и обхода графов.

**Очередь (FIFO — First In, First Out)** — это структура данных, в которой:
* добавление элементов (`enqueue`) выполняется в **конец очереди**;
* удаление (`dequeue`) происходит из **начала очереди**;
* элементы извлекаются в том же порядке, в котором были добавлены.
Очереди часто применяются для:
* буферизации данных,
* управления задачами (task scheduling),
* организации потоков данных.
  
## 2. Какие проблемы возникают при параллельном доступе к данным?

При параллельном доступе нескольких потоков к общим данным возникают следующие проблемы:

* **Состояние гонки (race condition)** — ситуация, когда результат выполнения зависит от порядка обращения потоков к данным.
* **Потеря данных** — несколько потоков могут одновременно записывать данные в одну область памяти.
* **Нарушение целостности структуры данных** — например, одновременное обновление указателей `top`, `head` или `tail` может привести к некорректному состоянию стека или очереди.
* **Несогласованность данных** — один поток может читать устаревшее или частично обновлённое значение.

Без правильной синхронизации такие проблемы делают параллельную структуру данных **непредсказуемой и некорректной**.

## 3. Как атомарные операции помогают избежать конфликтов в параллельных структурах данных?

Атомарные операции в CUDA (`atomicAdd`, `atomicSub`, и др.) гарантируют, что операция над общей переменной:

* выполняется **неделимо**;
* не может быть прервана другими потоками;
* корректно синхронизирует доступ к памяти.

В контексте параллельных структур данных атомарные операции:

* обеспечивают безопасное обновление индексов (`top`, `head`, `tail`);
* предотвращают одновременную запись в одну и ту же ячейку памяти;
* устраняют состояние гонки при добавлении и удалении элементов.

Таким образом, атомарные операции позволяют реализовать **lock-free** (без явных блокировок) версии стека и очереди на GPU.

## 4. Какие типы памяти CUDA используются для хранения данных?

В CUDA применяется несколько типов памяти, каждый из которых имеет свои особенности:

* **Глобальная память (Global Memory)**
  Доступна всем потокам и хосту, обладает большой ёмкостью, но высокой задержкой доступа. Используется для хранения основных данных структур.

* **Разделяемая память (Shared Memory)**
  Общая для потоков одного блока, имеет низкую задержку доступа и высокую пропускную способность. Особенно эффективна для временных данных и оптимизации доступа.

* **Локальная память (Local Memory)**
  Используется для хранения локальных переменных потоков, фактически размещается в глобальной памяти и имеет сравнительно медленный доступ.

Грамотное сочетание этих типов памяти позволяет существенно повысить производительность параллельных алгоритмов.

## 5. Как синхронизация потоков влияет на производительность?

Синхронизация необходима для корректности вычислений, однако она может:

* приводить к **простоям потоков**, ожидающих завершения операций других потоков;
* снижать степень параллелизма;
* увеличивать время выполнения ядра.

Использование атомарных операций также может стать узким местом при высокой конкуренции за общий ресурс. Поэтому при проектировании параллельных структур данных важно:

* минимизировать количество синхронизирующих операций;
* избегать избыточных барьеров синхронизации;
* эффективно распределять работу между потоками.

## 6. Почему разделяемая память важна для оптимизации работы параллельных структур данных?

Разделяемая память является ключевым инструментом оптимизации, поскольку:

* обеспечивает **значительно более быстрый доступ**, чем глобальная память;
* позволяет потокам одного блока эффективно обмениваться данными;
* снижает количество обращений к глобальной памяти;
* уменьшает задержки и повышает пропускную способность.

При реализации параллельных структур данных разделяемая память может использоваться для:

* хранения временных буферов;
* кэширования часто используемых данных;
* ускорения операций добавления и извлечения элементов.

Это делает её особенно важной для высокопроизводительных реализаций на GPU.
