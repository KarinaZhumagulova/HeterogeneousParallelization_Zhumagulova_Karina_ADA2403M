# Практическая работа №5

## Реализация параллельных структур данных на GPU

**Astana IT University**

**Курс:** Heterogeneous Parallelization

**Преподаватель:** Садвакасова Куралай Жанжигитовна

**Студент:** Жумагулова Карина

**Группа:** ADA-2403M

**Дата:** 17.01.2026

## Краткое описание практической работы

Данная практическая работа посвящена изучению и реализации **параллельных структур данных на графическом процессоре (GPU)** с использованием технологии **CUDA**.
В рамках работы реализованы две основные структуры данных — **стек (LIFO)** и **очередь (FIFO)**, обеспечивающие безопасный параллельный доступ из множества потоков за счёт применения **атомарных операций**.

Также проведено **экспериментальное сравнение производительности** операций вставки и удаления для параллельного стека и очереди.

## Цель работы

* Освоить принципы реализации параллельных структур данных с использованием CUDA.
* Реализовать параллельные версии **стека** и **очереди** с использованием атомарных операций.
* Исследовать и сравнить производительность операций `push/pop` и `enqueue/dequeue` на GPU.

## Структура репозитория

```
.
├── task_1_stack.cu        # Реализация параллельного стека (LIFO) на CUDA
├── task_2_5_queue.cu     # Реализация параллельной очереди (FIFO) на CUDA
├── HP_Practice_5.ipynb   # Jupyter Notebook для компиляции и запуска в Google Colab
├── questions.md          # Ответы на контрольные вопросы
├── README.md             # Описание проекта
```

## Теоретическая часть

### Параллельные структуры данных

Параллельные структуры данных — это структуры, которые поддерживают **безопасный доступ к данным из нескольких потоков одновременно**.
При их реализации необходимо учитывать:

* синхронизацию доступа,
* предотвращение гонок данных,
* минимизацию конфликтов при обращении к памяти.

### Основные структуры данных

* **Стек (LIFO)**
  Добавление и удаление элементов происходит с одного конца (вершины стека).

* **Очередь (FIFO)**
  Добавление элементов происходит в конец, а удаление — из начала.

### Применение параллельных структур данных

* буферизация данных;
* задачи планирования (Task Scheduling);
* организация потоков данных в параллельных алгоритмах.

## Программирование с использованием CUDA

CUDA — это платформа параллельных вычислений, позволяющая использовать GPU для выполнения вычислений общего назначения.

### Ключевые концепции CUDA

* **Потоки и блоки** — модель масштабируемого параллелизма.
* **Память CUDA**:

  * глобальная память,
  * разделяемая память,
  * локальная память.
* **Синхронизация** — атомарные операции и барьеры.

В данной работе **глобальная память GPU** используется для хранения структур данных, а **атомарные операции** обеспечивают корректность параллельного доступа.

## Практическая часть

### Общая характеристика

Практическая часть включает две независимые реализации:

1. **Параллельный стек (LIFO)**
2. **Параллельная очередь (FIFO)**

Для каждой структуры:

* реализована инициализация,
* выполнены параллельные операции вставки и удаления,
* измерено время выполнения операций,
* проверена корректность работы.

## Часть 1. Реализация параллельного стека (LIFO)

### Описание задания

Реализовать структуру данных **стек** с использованием атомарных операций CUDA для безопасного параллельного доступа.

### Реализация

* Стек размещён в **глобальной памяти GPU**.
* Вершина стека (`top`) обновляется с помощью `atomicAdd` и `atomicSub`.
* Поддерживается инициализация стека фиксированного размера.

### Функционал

* параллельный `push`;
* параллельный `pop`;
* проверка корректности LIFO-поведения;
* вывод первых и последних элементов;
* измерение времени выполнения операций.

## Часть 2. Реализация параллельной очереди (FIFO)

### Описание задания

Реализовать структуру данных **очередь** с использованием атомарных операций для безопасного параллельного добавления и удаления элементов.

### Реализация

* Очередь хранится в **глобальной памяти GPU**.
* Используются два атомарных указателя:

  * `head` — начало очереди,
  * `tail` — конец очереди.
* Операции `enqueue` и `dequeue` выполняются параллельно.

### Функционал

* параллельный `enqueue`;
* параллельный `dequeue`;
* проверка FIFO-порядка;
* вывод содержимого очереди до и после операций;
* измерение времени выполнения.

## Экспериментальные результаты

### Измеренные времена выполнения

| Структура      | Вставка (ms) | Удаление (ms) |
| -------------- | ------------ | ------------- |
| Стек (LIFO)    | 0.041        | 0.043         |
| Очередь (FIFO) | 0.069        | 0.040         |

## Анализ и сравнение производительности

* **Стек** показывает более высокую производительность при операциях вставки за счёт использования одного атомарного указателя.
* **Очередь** требует двух атомарных операций (`head` и `tail`), что увеличивает накладные расходы при `enqueue`.
* Операция `dequeue` в очереди демонстрирует хорошую эффективность благодаря последовательному доступу к памяти.
* Оба решения корректно работают в условиях параллельного доступа.

## Выводы

1. Реализованы параллельные структуры данных стек и очередь на GPU с использованием CUDA.
2. Атомарные операции обеспечивают корректный параллельный доступ без гонок данных.
3. Стек демонстрирует более высокую производительность при вставке элементов.
4. Очередь лучше подходит для сценариев с последовательным чтением данных.
5. Экспериментальные результаты подтверждают эффективность GPU для работы с динамическими структурами данных.

## Контрольные вопросы

Ответы на контрольные вопросы приведены в файле `questions.md`.

## Заключение

Практическая работа позволила изучить особенности реализации и оптимизации параллельных структур данных на GPU. Работа с динамическими структурами в параллельной среде требует особого внимания к синхронизации и управлению памятью, однако при корректной реализации позволяет достичь высокой производительности и масштабируемости.

