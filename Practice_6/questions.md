# Контрольные вопросы к Практической работе №6: Программирование на OpenCL для CPU и GPU

## 1. Какие основные типы памяти используются в OpenCL?
В OpenCL используется иерархическая модель памяти, включающая несколько уровней:
* **Глобальная память (Global memory)**
  Доступна всем рабочим элементам (work-items) и всем рабочим группам.
  Используется для хранения входных и выходных данных.
  Имеет большой объём, но относительно высокую задержку доступа.
* **Локальная память (Local memory)**
  Общая память для всех рабочих элементов внутри одной рабочей группы (work-group).
  Используется для обмена данными между рабочими элементами группы и оптимизации вычислений.
  По скорости доступа быстрее глобальной памяти.
* **Приватная память (Private memory)**
  Доступна только одному рабочему элементу.
  Обычно используется для хранения временных переменных и чаще всего размещается в регистрах.
* **Константная память (Constant memory)**
  Память только для чтения, доступная всем рабочим элементам.
  Оптимизирована для хранения неизменяемых данных, таких как коэффициенты или параметры алгоритма.

## 2. Как настроить глобальную и локальную рабочую группу в OpenCL?
Настройка размеров рабочих элементов выполняется при запуске ядра на выполнение с использованием модели **NDRange**.
* **Глобальный размер (Global Work Size)**
  Определяет общее количество рабочих элементов, которые будут выполнять ядро.
  Например, при обработке массива из `N` элементов глобальный размер обычно равен `N`.
* **Локальный размер (Local Work Size)**
  Определяет количество рабочих элементов в одной рабочей группе.
  Рабочие элементы внутри одной группы могут совместно использовать локальную память.
* **Программная настройка**
  Размеры глобальной и локальной рабочих групп задаются при вызове функции
  `clEnqueueNDRangeKernel`, где указываются параметры `global_work_size` и `local_work_size`.
Корректный выбор размеров рабочих групп оказывает существенное влияние на производительность программы.

## 3. Чем отличается OpenCL от CUDA?
Основные различия между OpenCL и CUDA заключаются в следующем:
* **Кросс-платформенность**
  OpenCL является открытым стандартом и поддерживает устройства различных производителей (CPU, GPU, FPGA).
  CUDA — проприетарная технология компании NVIDIA и работает только на её графических процессорах.
* **Аппаратная зависимость**
  OpenCL ориентирован на переносимость и универсальность.
  CUDA глубоко оптимизирован под архитектуру NVIDIA.
* **Сложность программирования**
  Программирование на OpenCL считается более сложным из-за необходимости явного управления платформами, устройствами и контекстами.
* **Производительность**
  CUDA часто демонстрирует более высокую производительность на GPU NVIDIA,
  тогда как OpenCL обеспечивает более широкую переносимость.

## 4. Какие преимущества дает использование OpenCL?
Использование OpenCL предоставляет следующие преимущества:
* **Кросс-платформенность**
  Возможность использовать один и тот же код на различных аппаратных платформах и устройствах.
* **Поддержка гетерогенных вычислений**
  OpenCL позволяет эффективно использовать вычислительные ресурсы CPU, GPU и других ускорителей.
* **Аппаратная независимость**
  Стандарт поддерживается многими производителями, что снижает зависимость от конкретного вендора.
* **Гибкость и масштабируемость**
  Программы на OpenCL легко адаптируются под разные размеры задач и архитектуры устройств.
