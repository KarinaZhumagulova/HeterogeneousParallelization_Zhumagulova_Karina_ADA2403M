# Практическая работа №6: Программирование на GPU с использованием CUDA

**Astana IT University**

**Курс:** Heterogeneous Parallelization

**Преподаватель:** Садвакасова Куралай Жанжигитовна

**Студент:** Жумагулова Карина

**Группа:** ADA-2403M

**Дата:** 18.01.2026

## Краткое описание практической работы

Данная практическая работа посвящена изучению **параллельных вычислений на GPU**. В рамках работы реализованы две задачи:

1. **Элементное сложение двух массивов** (Vector Addition)
2. **Умножение квадратных матриц** (Matrix Multiplication)

Для обеих задач использовалась технология **CUDA**. Проведено сравнение производительности между **CPU** и **GPU**, а также проверена корректность вычислений.

## Цель работы

* Освоить принципы параллельного программирования на GPU с использованием CUDA.
* Реализовать параллельное сложение массивов и умножение матриц.
* Провести экспериментальное сравнение производительности CPU и GPU.
* Проверить корректность результатов вычислений.

## Структура репозитория

```
.
├── task_1_array_addition.cu   # Параллельное сложение массивов на CUDA
├── task_2_matrix_multiplication.cu # Параллельное умножение матриц на CUDA
├── vector_add.ipynb           # Jupyter Notebook с примерами запуска в Colab
├── README.md                  # Этот файл
```

## Теоретическая часть

### Параллельные вычисления на GPU

GPU позволяет выполнять вычисления с **высокой степенью параллелизма**, используя множество потоков. Основные концепции CUDA:

* **Потоки и блоки** – модель масштабируемого параллелизма.
* **Память CUDA**:

  * глобальная память – доступна всем потокам, медленнее, но большая.
  * локальная память – приватная для каждого потока.
  * shared memory – совместная память внутри блока, быстрая.
* **Синхронизация** – использование `cudaDeviceSynchronize()` и атомарных операций при необходимости.

### Важность проверки корректности

При параллельных вычислениях важно сравнивать результат с **последовательной CPU версией**, чтобы убедиться, что нет ошибок гонок данных.

## Практическая часть

### Задача 1: Элементное сложение массивов

#### Описание

Необходимо сложить два массива A и B длиной N элементов, результат записать в массив C:

```
C[i] = A[i] + B[i]
```

#### Реализация

* CPU: последовательное сложение в цикле.
* GPU: каждый поток обрабатывает один элемент массива.
* Используется **глобальная память GPU** для хранения массивов.
* Размер блока потоков: 256.

#### Примеры данных

| Размер     | CPU (ms) | GPU (ms) | Speedup |
| ---------- | -------- | -------- | ------- |
| 10         | 0.00033  | 0.126    | 0.003   |
| 100        | 0.00049  | 0.016    | 0.03    |
| 1000       | 0.00306  | 0.016    | 0.19    |
| 10000      | 0.0289   | 0.013    | 2.16    |
| 100000     | 0.305    | 0.016    | 19.37   |
| 1 000 000  | 3.043    | 0.055    | 55.65   |
| 10 000 000 | 39.996   | 0.473    | 84.61   |

*Вывод*: GPU демонстрирует значительное ускорение для больших массивов.

#### Пример вывода (N=10)

```
First 10 elements:
A[0]=12345  B[0]=-2345  C[0]=10000
A[1]=-54321 B[1]=3210  C[1]=-51111
...
Last 10 elements:
A[0]=...   B[0]=...    C[0]=...
```

### Задача 2: Умножение матриц

#### Описание

Вычисление произведения двух квадратных матриц A и B размера N×N:

```
C[i][j] = Σ A[i][k] * B[k][j]
```

#### Реализация

* CPU: классическое тройное вложенное цикловое умножение.
* GPU: каждый поток вычисляет один элемент матрицы C.
* Размер блока потоков: 16x16.
* Используется глобальная память GPU.

#### Примеры данных

**Матрицы 3x3 (случайные числа от -100 до 100)**

```
Matrix A:
12  -5  23
-7  8   14
9   -3  6

Matrix B:
5   3  -2
-1  4   7
8   -6  9

Matrix C (CPU & GPU):
242  -95  145
87   100  112
59   -51  45

Correctness: OK
```

*Вывод*: GPU правильно вычисляет элементы матриц, совпадая с CPU версией.

## Экспериментальные результаты

* GPU обеспечивает значительное ускорение для больших массивов и матриц.
* Для маленьких размеров накладные расходы на запуск ядра могут превышать выигрыш.
* Проверка корректности показала, что результаты GPU и CPU совпадают.

## Контрольные вопросы

Ответы на контрольные вопросы приведены в файле `questions.md`.

## Выводы

1. Реализовано параллельное сложение массивов и умножение матриц на GPU.
2. GPU обеспечивает значительное ускорение для больших данных.
3. Результаты GPU совпадают с эталонными вычислениями на CPU.
4. Работа позволила изучить основы параллельного программирования на CUDA.
