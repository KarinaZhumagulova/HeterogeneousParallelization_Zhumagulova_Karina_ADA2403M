# Практическая работа №6: Программирование на GPU с использованием CUDA

**Astana IT University**

**Курс:** Heterogeneous Parallelization

**Преподаватель:** Садвакасова Куралай Жанжигитовна

**Студент:** Жумагулова Карина

**Группа:** ADA-2403M

**Дата:** 18.01.2026

## Краткое описание практической работы

Данная практическая работа посвящена изучению **параллельных вычислений на GPU**. В рамках работы реализованы две задачи:

1. **Элементное сложение двух массивов** (Vector Addition)
2. **Умножение квадратных матриц** (Matrix Multiplication)

Для обеих задач использовалась технология **CUDA**. Проведено сравнение производительности между **CPU** и **GPU**, а также проверена корректность вычислений.

## Цель работы

* Освоить принципы параллельного программирования на GPU с использованием CUDA.
* Реализовать параллельное сложение массивов и умножение матриц.
* Провести экспериментальное сравнение производительности CPU и GPU.
* Проверить корректность результатов вычислений.

## Структура репозитория

```
.
├── task_1_array_addition.cu   # Параллельное сложение массивов на CUDA
├── task_2_matrix_multiplication.cu # Параллельное умножение матриц на CUDA
├── HP_Practice_6.ipynb           # Jupyter Notebook с примерами запуска в Colab
├── README.md                  # Этот файл
```

## Теоретическая часть

### Параллельные вычисления на GPU

GPU позволяет выполнять вычисления с **высокой степенью параллелизма**, используя множество потоков. Основные концепции CUDA:

* **Потоки и блоки** – модель масштабируемого параллелизма.
* **Память CUDA**:

  * глобальная память – доступна всем потокам, медленнее, но большая.
  * локальная память – приватная для каждого потока.
  * shared memory – совместная память внутри блока, быстрая.
* **Синхронизация** – использование `cudaDeviceSynchronize()` и атомарных операций при необходимости.

### Важность проверки корректности

При параллельных вычислениях важно сравнивать результат с **последовательной CPU версией**, чтобы убедиться, что нет ошибок гонок данных.

## Практическая часть

### Задача 1: Элементное сложение массивов

#### Описание

Необходимо сложить два массива A и B длиной N элементов, результат записать в массив C:

```
C[i] = A[i] + B[i]
```

#### Реализация

* CPU: последовательное сложение в цикле.
* GPU: каждый поток обрабатывает один элемент массива.
* Используется **глобальная память GPU** для хранения массивов.
* Размер блока потоков: 256.

#### Примеры данных

| Размер массива (N) | Время CPU (ms) | Время GPU (ms) | Speedup |
| ------------------ | -------------- | -------------- | ------- |
| 10                 | 0.000306       | 0.104704       | 0.00292 |
| 100                | 0.000486       | 0.016224       | 0.02996 |
| 1000               | 0.003059       | 0.016128       | 0.18967 |
| 10000              | 0.029029       | 0.014112       | 2.05704 |
| 100000             | 0.290714       | 0.022080       | 13.1664 |
| 1000000            | 2.9968         | 0.054784       | 54.7021 |
| 10000000           | 39.3724        | 0.469408       | 64.7035 |


*Вывод*: GPU демонстрирует значительное ускорение для больших массивов.

#### Пример вывода (N=100)

```
First 10 elements:
A[0]=-62535  B[0]=72279  C[0]=9744
A[1]=44123  B[1]=-93470  C[1]=-49347
...
Last 10 elements:
...
A[98]=10028  B[98]=-7336  C[98]=2692
A[99]=-70174  B[99]=81605  C[99]=11431
```

### Задача 2: Умножение матриц

#### Описание

Вычисление произведения двух квадратных матриц A и B размера N×N:

```
C[i][j] = Σ A[i][k] * B[k][j]
```

#### Реализация

* CPU: классическое тройное вложенное цикловое умножение.
* GPU: каждый поток вычисляет один элемент матрицы C.
* Размер блока потоков: 16x16.
* Используется глобальная память GPU.

#### Примеры данных

**Матрицы 3x3 (случайные числа от -100 до 100)**

```
Matrix size: 3x3
Matrix A:
-69	-11	-69	
-80	-89	-8	
74	-33	20	

Matrix B:
-72	42	30	
-96	-89	94	
45	67	88	

Matrix C (CPU):
2919	-6542	-9176	
13944	4025	-11470	
-1260	7385	878	

Matrix C (GPU):
2919	-6542	-9176	
13944	4025	-11470	
-1260	7385	878	

Correctness: OK
```

*Вывод*: GPU правильно вычисляет элементы матриц, совпадая с CPU версией.

## Экспериментальные результаты

* GPU обеспечивает значительное ускорение для больших массивов и матриц.
* Для маленьких размеров накладные расходы на запуск ядра могут превышать выигрыш.
* Проверка корректности показала, что результаты GPU и CPU совпадают.

## Контрольные вопросы

Ответы на контрольные вопросы приведены в файле `questions.md`.

## Выводы

1. Реализовано параллельное сложение массивов и умножение матриц на GPU.
2. GPU обеспечивает значительное ускорение для больших данных.
3. Результаты GPU совпадают с эталонными вычислениями на CPU.
4. Работа позволила изучить основы параллельного программирования на CUDA.

## Примечание
В данной практической работе предполагалось использовать OpenCL для реализации параллельного сложения массивов. Однако на текущей системе возникли проблемы с установкой и совместимостью драйверов OpenCL, поэтому для выполнения задания был использован CUDA. Несмотря на это, логика параллельных вычислений полностью сохраняется, а результаты позволяют продемонстрировать разницу в производительности между CPU и GPU.
