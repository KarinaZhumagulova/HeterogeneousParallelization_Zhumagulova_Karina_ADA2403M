# Практическая работа №10: Профилирование и оптимизация параллельных и гибридных приложений

**Astana IT University**

**Курс:** Heterogeneous Parallelization

**Преподаватель:** Садвакасова Куралай Жанжигитовна

**Студент:** Жумагулова Карина

**Группа:** ADA-2403M

**Дата:** 25.01.2026

## Краткое описание практической работы

Данная практическая работа посвящена **анализу производительности, профилированию и оптимизации параллельных программ**, реализованных с использованием технологий:

* **OpenMP** (CPU-параллелизм),
* **CUDA** (GPU-вычисления),
* **MPI** (распределённые вычисления),
* **гибридных CPU + GPU решений**.

Основная цель работы — изучить, **как архитектура вычислений, доступ к памяти и коммуникации между CPU и GPU влияют на производительность**, а также научиться выявлять узкие места и применять оптимизации.

В рамках работы реализованы четыре задания:

1. Анализ производительности CPU-параллельной программы (OpenMP).
2. Анализ и оптимизация доступа к памяти на GPU (CUDA).
3. Профилирование гибридного приложения CPU + GPU.
4. Анализ масштабируемости распределённой программы (MPI).

Для всех заданий:

* выполнены **замеры времени выполнения**,
* проведено **профилирование отдельных этапов вычислений**,
* сделаны выводы о масштабируемости и узких местах.

## Цель работы

* Изучить методы **профилирования параллельных программ**.
* Проанализировать влияние числа потоков и процессов на ускорение.
* Исследовать **накладные расходы передачи данных** между CPU и GPU.
* Освоить оптимизации памяти (coalesced access, shared memory, pinned memory).
* Проанализировать масштабируемость с точки зрения **законов Амдала и Густафсона**.

## Структура репозитория

```
.
├── task_1_openmp.cpp        # OpenMP: анализ CPU-параллелизма
├── task_2_cuda_memory.cu    # CUDA: доступ к памяти и оптимизация
├── task_3_hybrid.cu         # Гибридное CPU + GPU приложение
├── task_4_mpi.cpp           # MPI: strong и weak scaling
├── questions.md             # Ответы на контрольные вопросы
├── README.md                # Этот файл
```

## Теоретическая часть

### Профилирование параллельных программ

**Профилирование** — это процесс измерения:

* времени выполнения отдельных частей программы,
* загрузки вычислительных ресурсов,
* накладных расходов синхронизации и передачи данных.

В данной работе используются:

* `omp_get_wtime()` — для CPU (OpenMP),
* `cudaEventRecord()` — для GPU,
* `MPI_Wtime()` — для распределённых программ.

## Практическая часть

## Задание 1: Анализ производительности CPU-параллельной программы (OpenMP)

**Цель:**
Реализовать параллельную обработку массива данных с использованием OpenMP и проанализировать влияние числа потоков на ускорение.

**Описание реализации:**

* Вычисление суммы, среднего значения и дисперсии большого массива.
* Использование директив `#pragma omp parallel for`.
* Замер времени выполнения с помощью `omp_get_wtime()`.

**Анализ:**

* Определена доля последовательной и параллельной части.
* Исследовано ускорение при различном числе потоков.
* Результаты проанализированы с точки зрения **закона Амдала**.

**Выводы:**

* Увеличение числа потоков эффективно до определённого предела.
* Последовательная часть программы ограничивает максимальное ускорение.

---

## Задание 2: Оптимизация доступа к памяти на GPU (CUDA)

**Цель:**
Исследовать влияние паттернов доступа к глобальной памяти GPU на производительность.

**Описание реализации:**

* Реализованы две версии CUDA-ядра:

  * с коалесцированным доступом к памяти;
  * с некоалесцированным доступом.
* Замеры времени выполнены с использованием `cudaEvent`.

**Оптимизации:**

* Использование **shared memory**.
* Изменение организации потоков и блоков.

**Выводы:**

* Коалесцированный доступ значительно снижает время выполнения.
* Shared memory уменьшает число обращений к глобальной памяти и повышает производительность.

---

## Задание 3: Профилирование гибридного приложения CPU + GPU

**Цель:**
Разработать гибридную программу, в которой часть вычислений выполняется на CPU, а часть — на GPU, и провести детальное профилирование.

**Описание реализации:**

* CPU вычисляет сумму и среднее значение массива.
* GPU вычисляет дисперсию массива.
* Используются:

  * `cudaMemcpyAsync`,
  * `cudaStream`,
  * CUDA events для раздельного измерения времени.

**Профилируемые этапы GPU:**

* Host → Device (H2D) copy,
* выполнение CUDA-ядра,
* Device → Host (D2H) copy.

**Оптимизация:**

* Реализовано использование **pinned (page-locked) memory**:

  ```cpp
  cudaMallocHost(&h_data, N * sizeof(float));
  ```
* Это позволило снизить накладные расходы передачи данных.

**Пример результата профилирования:**

```
CPU time (s):        0.000140
H2D time (s):        0.000027
Kernel time (s):     0.000061
D2H time (s):        0.000016
GPU total time (s):  0.000104
Hybrid total time (s): 0.000244
```

**Выводы:**

* Основные накладные расходы приходятся на передачу данных.
* Использование pinned memory уменьшает время H2D и D2H копирования.
* Для небольших массивов CPU быстрее, для больших — GPU даёт выигрыш.

---

## Задание 4: Анализ масштабируемости распределённой программы (MPI)

**Цель:**
Оценить **strong scaling** и **weak scaling** MPI-программы.

**Описание:**

* Реализовано вычисление агрегатной функции над массивом.
* Использованы `MPI_Reduce` и `MPI_Allreduce`.
* Выполнены замеры времени при различном числе процессов.

**Анализ:**

* Strong scaling: фиксированный размер задачи.
* Weak scaling: размер задачи растёт пропорционально числу процессов.

**Выводы:**

* Коммуникационные операции ограничивают масштабируемость.
* MPI эффективен для больших задач и умеренного числа процессов.

---

## Контрольные вопросы

Ответы на контрольные вопросы приведены в файле **questions.md**.

---

## Заключение

В ходе практической работы были:

* изучены методы профилирования CPU, GPU и распределённых программ;
* реализованы и оптимизированы параллельные и гибридные алгоритмы;
* проанализированы накладные расходы и узкие места;
* продемонстрировано влияние архитектуры и памяти на производительность.

Практическая работа дала целостное понимание **HPC-подходов и гибридных вычислений**, а также показала важность профилирования при разработке эффективных параллельных программ.

